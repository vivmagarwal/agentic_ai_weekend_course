{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# **Advanced Output Parsing with LangChain**\n\n## **Learning Objectives**\nBy the end of this notebook, you will be able to:\n- Master all types of output parsers in LangChain\n- Handle complex nested data structures\n- Implement custom parsers for specific needs\n- Fix parsing errors and handle edge cases\n- Use structured output with function calling\n- Validate and transform parsed data\n\n## **Why This Matters: Structured Data from Unstructured Text**\n\n**In Production Systems:**\n- Convert LLM responses to database records\n- Extract structured data for APIs\n- Ensure type safety and validation\n\n**In Data Processing:**\n- Parse documents into structured formats\n- Extract entities and relationships\n- Transform text into actionable data\n\n**In Application Integration:**\n- Feed LLM outputs to downstream systems\n- Maintain data contracts between components\n- Enable reliable automation\n\n## **Prerequisites**\n- Completed notebooks 00-03\n- Understanding of JSON and data structures\n- Basic knowledge of Pydantic (helpful but not required)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## **Setup: Install and Import Dependencies**\n\nRun this cell first to set up your environment:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q langchain langchain-openai pydantic python-dotenv pandas\n",
    "\n",
    "# Import necessary modules\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict, Optional, Union\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import (\n",
    "    StrOutputParser,\n",
    "    JsonOutputParser,\n",
    "    PydanticOutputParser,\n",
    "    CommaSeparatedListOutputParser,\n",
    "    StructuredOutputParser,\n",
    "    ResponseSchema\n",
    ")\n",
    "from langchain.output_parsers import OutputFixingParser, RetryOutputParser\n",
    "from pydantic import BaseModel, Field, validator, ValidationError\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Verify setup\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"‚úÖ Environment ready! Let's master output parsing.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Please set your OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## **Instructor Activity 1: Advanced Pydantic Parsing**\n\n**Concept**: Use Pydantic's advanced features for complex data validation and transformation.\n\n### **Example 1: Nested Models with Validation**\n\n**Problem**: Parse complex nested structures with validation\n**Expected Output**: Validated nested data models"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty cell for demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Solution</summary>\n\n```python\nfrom pydantic import BaseModel, Field, validator\nfrom typing import List, Optional\nfrom datetime import datetime\nfrom enum import Enum\nfrom langchain_core.output_parsers import PydanticOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\n\n# **Define enums for valid values**\nclass Priority(str, Enum):\n    LOW = \"low\"\n    MEDIUM = \"medium\"\n    HIGH = \"high\"\n    CRITICAL = \"critical\"\n\nclass TaskStatus(str, Enum):\n    TODO = \"todo\"\n    IN_PROGRESS = \"in_progress\"\n    DONE = \"done\"\n    BLOCKED = \"blocked\"\n\n# **Define nested models**\nclass Subtask(BaseModel):\n    title: str = Field(description=\"Subtask title\")\n    completed: bool = Field(description=\"Whether subtask is completed\")\n    estimated_hours: float = Field(description=\"Estimated hours to complete\", gt=0, le=40)\n\nclass Assignee(BaseModel):\n    name: str = Field(description=\"Person's name\")\n    email: str = Field(description=\"Email address\")\n    department: str = Field(description=\"Department name\")\n    \n    @validator('email')\n    def email_must_be_valid(cls, v):\n        if '@' not in v:\n            raise ValueError('Invalid email address')\n        return v.lower()\n\nclass ProjectTask(BaseModel):\n    task_id: str = Field(description=\"Unique task identifier\")\n    title: str = Field(description=\"Task title\")\n    description: str = Field(description=\"Detailed task description\")\n    priority: Priority = Field(description=\"Task priority level\")\n    status: TaskStatus = Field(description=\"Current task status\")\n    assignee: Assignee = Field(description=\"Person assigned to the task\")\n    subtasks: List[Subtask] = Field(description=\"List of subtasks\")\n    due_date: str = Field(description=\"Due date in YYYY-MM-DD format\")\n    tags: List[str] = Field(description=\"Task tags for categorization\")\n    estimated_total_hours: Optional[float] = Field(None, description=\"Total estimated hours\")\n    \n    @validator('due_date')\n    def validate_date_format(cls, v):\n        try:\n            datetime.strptime(v, '%Y-%m-%d')\n        except ValueError:\n            raise ValueError('Date must be in YYYY-MM-DD format')\n        return v\n    \n    @validator('subtasks')\n    def at_least_one_subtask(cls, v):\n        if len(v) == 0:\n            raise ValueError('At least one subtask required')\n        return v\n    \n    @validator('estimated_total_hours', always=True)\n    def calculate_total_hours(cls, v, values):\n        if 'subtasks' in values:\n            return sum(st.estimated_hours for st in values['subtasks'])\n        return v\n\n# **Create parser**\ntask_parser = PydanticOutputParser(pydantic_object=ProjectTask)\n\n# **Create prompt**\nprompt = ChatPromptTemplate.from_template(\n    \"\"\"Extract project task information from this description:\n    \n    {description}\n    \n    {format_instructions}\n    \"\"\"\n)\n\n# **Build chain**\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\nchain = prompt | llm | task_parser\n\n# **Test with complex task description**\ndescription = \"\"\"Task #DEV-123: Implement User Authentication System\n\nThis is a high-priority task to implement a complete user authentication system.\nIt's currently in progress and assigned to John Smith (john.smith@company.com) from the Engineering department.\n\nThe task needs to be completed by 2024-04-15 and includes:\n1. Design database schema (3 hours) - completed\n2. Implement login API (5 hours) - not completed\n3. Create password reset flow (4 hours) - not completed\n4. Add two-factor authentication (6 hours) - not completed\n\nTags: security, backend, authentication, api\n\"\"\"\n\n# **Parse the task**\nresult = chain.invoke({\n    \"description\": description,\n    \"format_instructions\": task_parser.get_format_instructions()\n})\n\nprint(\"Complex Nested Model Parsing:\")\nprint(\"=\" * 50)\nprint(f\"üìã Task: {result.title}\")\nprint(f\"üîë ID: {result.task_id}\")\nprint(f\"üìä Status: {result.status.value}\")\nprint(f\"üî¥ Priority: {result.priority.value}\")\nprint(f\"üìÖ Due: {result.due_date}\")\nprint(f\"\\nüë§ Assignee:\")\nprint(f\"  Name: {result.assignee.name}\")\nprint(f\"  Email: {result.assignee.email}\")\nprint(f\"  Dept: {result.assignee.department}\")\nprint(f\"\\nüìù Subtasks ({len(result.subtasks)}):\")\nfor i, subtask in enumerate(result.subtasks, 1):\n    status = \"‚úÖ\" if subtask.completed else \"‚è≥\"\n    print(f\"  {i}. {status} {subtask.title} ({subtask.estimated_hours}h)\")\nprint(f\"\\n‚è∞ Total Estimated Hours: {result.estimated_total_hours}\")\nprint(f\"üè∑Ô∏è Tags: {', '.join(result.tags)}\")\n\nprint(\"\\n‚úÖ Complex nested validation successful!\")\n```\n\n**Advanced Pydantic features:**\n- Nested model composition\n- Enum validation for fixed choices\n- Custom validators for business logic\n- Computed fields from other fields\n\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### **Example 2: Handling Lists and Optional Fields**\n\n**Problem**: Parse variable structures with optional data\n**Expected Output**: Flexible data models"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty cell for demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Solution</summary>\n\n```python\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional, Union\nfrom langchain_core.output_parsers import PydanticOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\n# **Define flexible models**\nclass ContactInfo(BaseModel):\n    type: str = Field(description=\"Contact type: email, phone, social\")\n    value: str = Field(description=\"Contact value\")\n    preferred: bool = Field(default=False, description=\"Is this preferred contact method\")\n\nclass Address(BaseModel):\n    street: Optional[str] = Field(None, description=\"Street address\")\n    city: str = Field(description=\"City name\")\n    state: Optional[str] = Field(None, description=\"State/Province\")\n    country: str = Field(description=\"Country\")\n    postal_code: Optional[str] = Field(None, description=\"Postal/ZIP code\")\n\nclass Experience(BaseModel):\n    company: str = Field(description=\"Company name\")\n    position: str = Field(description=\"Job title\")\n    duration: str = Field(description=\"Duration of employment\")\n    responsibilities: List[str] = Field(default_factory=list, description=\"Key responsibilities\")\n\nclass Skill(BaseModel):\n    name: str = Field(description=\"Skill name\")\n    level: str = Field(description=\"Proficiency level: beginner, intermediate, expert\")\n    years: Optional[int] = Field(None, description=\"Years of experience\")\n\nclass UserProfile(BaseModel):\n    name: str = Field(description=\"Full name\")\n    title: Optional[str] = Field(None, description=\"Professional title\")\n    contacts: List[ContactInfo] = Field(description=\"Contact information\")\n    address: Optional[Address] = Field(None, description=\"Physical address\")\n    skills: List[Skill] = Field(default_factory=list, description=\"Professional skills\")\n    experience: List[Experience] = Field(default_factory=list, description=\"Work experience\")\n    languages: List[str] = Field(default_factory=list, description=\"Languages spoken\")\n    certifications: Optional[List[str]] = Field(None, description=\"Professional certifications\")\n    bio: Optional[str] = Field(None, description=\"Short biography\")\n\n# **Create parser**\nprofile_parser = PydanticOutputParser(pydantic_object=UserProfile)\n\n# **Create prompt**\nprompt = ChatPromptTemplate.from_template(\n    \"\"\"Extract user profile information from this text:\n    \n    {text}\n    \n    Note: Some fields might be missing - that's okay.\n    {format_instructions}\n    \"\"\"\n)\n\n# **Build chain**\nchain = prompt | llm | profile_parser\n\n# **Test with different profile completeness**\nprofiles = [\n    \"\"\"Sarah Johnson is a Senior Data Scientist based in San Francisco, CA, USA.\n    You can reach her at sarah@email.com (preferred) or phone: 555-0123.\n    She has expert-level Python skills (5 years) and intermediate SQL knowledge.\n    Previously worked at TechCorp as Lead Analyst for 3 years, managing data pipelines.\n    She speaks English and Spanish, and holds AWS and Google Cloud certifications.\"\"\",\n    \n    \"\"\"Mike Chen - Software Developer\n    Contact: mike.chen@gmail.com\n    Lives in Toronto, Canada\n    Knows JavaScript (expert), React (intermediate), Node.js (intermediate)\"\"\"\n]\n\nprint(\"Flexible Model Parsing with Optional Fields:\")\nprint(\"=\" * 50)\n\nfor i, profile_text in enumerate(profiles, 1):\n    print(f\"\\nüìÑ Profile {i}:\")\n    \n    result = chain.invoke({\n        \"text\": profile_text,\n        \"format_instructions\": profile_parser.get_format_instructions()\n    })\n    \n    print(f\"üë§ Name: {result.name}\")\n    if result.title:\n        print(f\"üíº Title: {result.title}\")\n    \n    print(f\"üìû Contacts:\")\n    for contact in result.contacts:\n        pref = \" (preferred)\" if contact.preferred else \"\"\n        print(f\"  - {contact.type}: {contact.value}{pref}\")\n    \n    if result.address:\n        print(f\"üìç Location: {result.address.city}, {result.address.country}\")\n    \n    if result.skills:\n        print(f\"üéØ Skills:\")\n        for skill in result.skills:\n            years = f\" ({skill.years} years)\" if skill.years else \"\"\n            print(f\"  - {skill.name}: {skill.level}{years}\")\n    \n    if result.certifications:\n        print(f\"üèÜ Certifications: {', '.join(result.certifications)}\")\n    \n    print(f\"\\nFields populated: {sum(1 for field, value in result.dict().items() if value is not None)}\")\n\nprint(\"\\n‚úÖ Flexible parsing handles missing fields gracefully!\")\n```\n\n**Optional field benefits:**\n- Handles incomplete data gracefully\n- Provides defaults where appropriate\n- Flexible for real-world data\n- No errors for missing fields\n\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### **Example 3: Union Types and Polymorphic Models**\n\n**Problem**: Parse data that can be one of several types\n**Expected Output**: Polymorphic data handling"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty cell for demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Solution</summary>\n\n```python\nfrom pydantic import BaseModel, Field\nfrom typing import Union, List, Literal\nfrom langchain_core.output_parsers import PydanticOutputParser\n\n# **Define different event types**\nclass MeetingEvent(BaseModel):\n    event_type: Literal[\"meeting\"] = \"meeting\"\n    title: str\n    participants: List[str]\n    duration_minutes: int\n    meeting_link: Optional[str] = None\n\nclass DeadlineEvent(BaseModel):\n    event_type: Literal[\"deadline\"] = \"deadline\"\n    title: str\n    deliverable: str\n    responsible_person: str\n\nclass ReminderEvent(BaseModel):\n    event_type: Literal[\"reminder\"] = \"reminder\"\n    title: str\n    message: str\n    priority: str\n\n# **Union type for any event**\nEvent = Union[MeetingEvent, DeadlineEvent, ReminderEvent]\n\nclass Calendar(BaseModel):\n    date: str = Field(description=\"Date in YYYY-MM-DD format\")\n    events: List[Event] = Field(description=\"List of events for the day\")\n    total_events: int = Field(default=0)\n    \n    @validator('total_events', always=True)\n    def count_events(cls, v, values):\n        if 'events' in values:\n            return len(values['events'])\n        return 0\n\n# **Create parser**\ncalendar_parser = PydanticOutputParser(pydantic_object=Calendar)\n\n# **Create prompt**\nprompt = ChatPromptTemplate.from_template(\n    \"\"\"Extract calendar events from this schedule:\n    \n    {schedule}\n    \n    Identify the type of each event (meeting, deadline, or reminder).\n    {format_instructions}\n    \"\"\"\n)\n\n# **Test with mixed event types**\nschedule = \"\"\"Schedule for 2024-04-20:\n\n- Team standup meeting at 9 AM with John, Sarah, and Mike for 30 minutes (Zoom link: zoom.us/123)\n- DEADLINE: Submit quarterly report - Sarah is responsible\n- Product demo meeting at 2 PM with clients for 60 minutes\n- REMINDER: Review pull requests (high priority)\n- DEADLINE: Deploy v2.0 to production - Mike is responsible\n\"\"\"\n\nchain = prompt | llm | calendar_parser\nresult = chain.invoke({\n    \"schedule\": schedule,\n    \"format_instructions\": calendar_parser.get_format_instructions()\n})\n\nprint(\"Polymorphic Event Parsing:\")\nprint(\"=\" * 50)\nprint(f\"üìÖ Date: {result.date}\")\nprint(f\"üìä Total Events: {result.total_events}\\n\")\n\nfor i, event in enumerate(result.events, 1):\n    print(f\"Event {i} - Type: {event.event_type}\")\n    print(f\"  Title: {event.title}\")\n    \n    if event.event_type == \"meeting\":\n        print(f\"  Participants: {', '.join(event.participants)}\")\n        print(f\"  Duration: {event.duration_minutes} min\")\n        if event.meeting_link:\n            print(f\"  Link: {event.meeting_link}\")\n    elif event.event_type == \"deadline\":\n        print(f\"  Deliverable: {event.deliverable}\")\n        print(f\"  Responsible: {event.responsible_person}\")\n    elif event.event_type == \"reminder\":\n        print(f\"  Message: {event.message}\")\n        print(f\"  Priority: {event.priority}\")\n    print()\n\nprint(\"‚úÖ Union types handle different event structures!\")\n```\n\n**Union type advantages:**\n- Handle multiple data shapes\n- Type-safe polymorphism\n- Automatic type discrimination\n- Clean data modeling\n\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## **Learner Activity 1: Practice Advanced Parsing**\n\n**Practice Focus**: Create complex Pydantic models with validation\n\n### **Exercise 1: Build an Invoice Parser**\n\n**Task**: Create a parser for invoice data with line items\n**Expected Output**: Structured invoice with calculations"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# TODO: Create Pydantic models for:\n",
    "# - LineItem (product, quantity, unit_price, total)\n",
    "# - Invoice (invoice_number, date, customer, items, subtotal, tax, total)\n",
    "# Add validation for calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Solution</summary>\n\n```python\nfrom pydantic import BaseModel, Field, validator\nfrom typing import List\nfrom datetime import datetime\nfrom langchain_core.output_parsers import PydanticOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nclass LineItem(BaseModel):\n    product: str = Field(description=\"Product name\")\n    quantity: int = Field(description=\"Quantity ordered\", gt=0)\n    unit_price: float = Field(description=\"Price per unit\", gt=0)\n    total: float = Field(description=\"Line total\")\n    \n    @validator('total')\n    def validate_total(cls, v, values):\n        if 'quantity' in values and 'unit_price' in values:\n            expected = values['quantity'] * values['unit_price']\n            if abs(v - expected) > 0.01:  # Allow small rounding differences\n                return expected  # Auto-correct\n        return v\n\nclass Customer(BaseModel):\n    name: str = Field(description=\"Customer name\")\n    company: Optional[str] = Field(None, description=\"Company name\")\n    email: str = Field(description=\"Customer email\")\n\nclass Invoice(BaseModel):\n    invoice_number: str = Field(description=\"Invoice number\")\n    date: str = Field(description=\"Invoice date in YYYY-MM-DD\")\n    customer: Customer = Field(description=\"Customer information\")\n    items: List[LineItem] = Field(description=\"Line items\")\n    subtotal: float = Field(description=\"Subtotal before tax\")\n    tax_rate: float = Field(description=\"Tax rate as decimal\", ge=0, le=1)\n    tax_amount: float = Field(description=\"Tax amount\")\n    total: float = Field(description=\"Total amount due\")\n    \n    @validator('subtotal')\n    def calculate_subtotal(cls, v, values):\n        if 'items' in values:\n            calculated = sum(item.total for item in values['items'])\n            return calculated\n        return v\n    \n    @validator('tax_amount')\n    def calculate_tax(cls, v, values):\n        if 'subtotal' in values and 'tax_rate' in values:\n            return values['subtotal'] * values['tax_rate']\n        return v\n    \n    @validator('total')\n    def calculate_total(cls, v, values):\n        if 'subtotal' in values and 'tax_amount' in values:\n            return values['subtotal'] + values['tax_amount']\n        return v\n\n# **Create parser and prompt**\ninvoice_parser = PydanticOutputParser(pydantic_object=Invoice)\n\nprompt = ChatPromptTemplate.from_template(\n    \"\"\"Extract invoice information from this text:\n    \n    {invoice_text}\n    \n    {format_instructions}\n    \"\"\"\n)\n\n# **Test with invoice text**\ninvoice_text = \"\"\"Invoice #INV-2024-001\nDate: April 15, 2024\n\nBill To:\nJohn Doe\nAcme Corporation\njohn@acme.com\n\nItems:\n1. Premium Widget - Qty: 5 @ $29.99 each\n2. Standard Gadget - Qty: 10 @ $15.50 each\n3. Deluxe Tool - Qty: 2 @ $89.00 each\n\nTax Rate: 8.5%\n\"\"\"\n\nchain = prompt | llm | invoice_parser\nresult = chain.invoke({\n    \"invoice_text\": invoice_text,\n    \"format_instructions\": invoice_parser.get_format_instructions()\n})\n\nprint(\"Invoice Parsing with Calculations:\")\nprint(\"=\" * 50)\nprint(f\"üìÑ Invoice: {result.invoice_number}\")\nprint(f\"üìÖ Date: {result.date}\")\nprint(f\"\\nüë§ Customer:\")\nprint(f\"  Name: {result.customer.name}\")\nif result.customer.company:\n    print(f\"  Company: {result.customer.company}\")\nprint(f\"  Email: {result.customer.email}\")\n\nprint(f\"\\nüì¶ Line Items:\")\nfor item in result.items:\n    print(f\"  ‚Ä¢ {item.product}: {item.quantity} √ó ${item.unit_price:.2f} = ${item.total:.2f}\")\n\nprint(f\"\\nüí∞ Totals:\")\nprint(f\"  Subtotal: ${result.subtotal:.2f}\")\nprint(f\"  Tax ({result.tax_rate*100:.1f}%): ${result.tax_amount:.2f}\")\nprint(f\"  Total Due: ${result.total:.2f}\")\n\nprint(\"\\n‚úÖ Invoice parsed with automatic calculations!\")\n```\n\n**What you learned:**\n- Validators for automatic calculations\n- Nested customer model\n- Financial data validation\n- Self-correcting totals\n\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## **Instructor Activity 2: Error Handling and Recovery**\n\n**Concept**: Handle parsing errors gracefully and implement retry logic.\n\n### **Example 1: Output Fixing Parser**\n\n**Problem**: Automatically fix malformed LLM outputs\n**Expected Output**: Corrected and parsed data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty cell for demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Solution</summary>\n\n```python\nfrom langchain.output_parsers import OutputFixingParser\nfrom langchain_core.output_parsers import JsonOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\nfrom pydantic import BaseModel, Field\n\n# **Define expected structure**\nclass ProductReview(BaseModel):\n    product_name: str = Field(description=\"Name of the product\")\n    rating: int = Field(description=\"Rating from 1 to 5\", ge=1, le=5)\n    pros: List[str] = Field(description=\"List of pros\")\n    cons: List[str] = Field(description=\"List of cons\")\n    summary: str = Field(description=\"Brief summary\")\n\n# **Create base parser**\nbase_parser = JsonOutputParser(pydantic_object=ProductReview)\n\n# **Wrap with OutputFixingParser**\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\nfixing_parser = OutputFixingParser.from_llm(parser=base_parser, llm=llm)\n\n# **Test with malformed outputs**\nmalformed_outputs = [\n    # Missing quotes around keys\n    \"\"\"{product_name: \"Laptop\", rating: 4, pros: [\"Fast\", \"Lightweight\"], cons: [\"Expensive\"], summary: \"Good laptop\"}\"\"\",\n    \n    # Invalid JSON with trailing comma\n    \"\"\"{\n        \"product_name\": \"Phone\",\n        \"rating\": 5,\n        \"pros\": [\"Great camera\", \"Long battery\",],\n        \"cons\": [\"No headphone jack\"],\n        \"summary\": \"Excellent phone\"\n    }\"\"\",\n    \n    # Missing field\n    \"\"\"{\n        \"product_name\": \"Tablet\",\n        \"rating\": 3,\n        \"pros\": [\"Good screen\"],\n        \"cons\": [\"Slow processor\"]\n    }\"\"\"\n]\n\nprint(\"Output Fixing Parser Demo:\")\nprint(\"=\" * 50)\n\nfor i, malformed in enumerate(malformed_outputs, 1):\n    print(f\"\\nüîß Test {i}: Fixing malformed output\")\n    print(f\"Input: {malformed[:50]}...\")\n    \n    try:\n        # Try base parser first (will fail)\n        result = base_parser.parse(malformed)\n        print(\"‚úÖ Base parser succeeded (unexpected!)\")\n    except Exception as e:\n        print(f\"‚ùå Base parser failed: {str(e)[:50]}\")\n        \n        # Use fixing parser\n        try:\n            fixed_result = fixing_parser.parse(malformed)\n            print(f\"‚úÖ Fixing parser succeeded!\")\n            print(f\"  Product: {fixed_result['product_name']}\")\n            print(f\"  Rating: {fixed_result['rating']}/5\")\n            if 'summary' in fixed_result:\n                print(f\"  Summary: {fixed_result['summary']}\")\n        except Exception as e2:\n            print(f\"‚ùå Fixing parser also failed: {str(e2)[:50]}\")\n\nprint(\"\\nüí° OutputFixingParser uses LLM to fix malformed outputs!\")\n```\n\n**Output fixing benefits:**\n- Handles malformed JSON\n- Adds missing fields\n- Fixes syntax errors\n- Improves reliability\n\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### **Example 2: Retry Parser with Better Instructions**\n\n**Problem**: Retry parsing with improved prompts\n**Expected Output**: Successful parsing after retry"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty cell for demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Solution</summary>\n\n```python\nfrom langchain.output_parsers import RetryOutputParser\nfrom langchain_core.output_parsers import PydanticOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom pydantic import BaseModel, Field, validator\n\n# **Define strict model**\nclass FinancialReport(BaseModel):\n    company_name: str = Field(description=\"Company name\")\n    ticker: str = Field(description=\"Stock ticker symbol\")\n    revenue: float = Field(description=\"Revenue in millions\", gt=0)\n    profit_margin: float = Field(description=\"Profit margin as decimal\", ge=0, le=1)\n    year_over_year_growth: float = Field(description=\"YoY growth as decimal\")\n    recommendation: str = Field(description=\"Buy, Hold, or Sell\")\n    \n    @validator('ticker')\n    def ticker_uppercase(cls, v):\n        return v.upper()\n    \n    @validator('recommendation')\n    def valid_recommendation(cls, v):\n        if v.lower() not in ['buy', 'hold', 'sell']:\n            raise ValueError('Recommendation must be Buy, Hold, or Sell')\n        return v.capitalize()\n\n# **Create parsers**\nbase_parser = PydanticOutputParser(pydantic_object=FinancialReport)\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n\n# **Create retry parser**\nretry_parser = RetryOutputParser.from_llm(\n    parser=base_parser,\n    llm=llm,\n    max_retries=2\n)\n\n# **Create initial prompt (might produce errors)**\ninitial_prompt = ChatPromptTemplate.from_template(\n    \"\"\"Extract financial data from: {text}\n    Format as JSON.\"\"\"\n)\n\n# **Test text**\nfinancial_text = \"\"\"TechCorp (ticker: TECH) reported strong Q4 results with revenue of $450 million,\nup 23% year-over-year. The company maintained a healthy profit margin of 18.5%.\nAnalysts recommend this as a strong buy opportunity.\"\"\"\n\nprint(\"Retry Parser Demo:\")\nprint(\"=\" * 50)\n\n# **First attempt (might fail due to lack of format instructions)**\nchain = initial_prompt | llm\ninitial_completion = chain.invoke({\"text\": financial_text})\n\nprint(\"Initial LLM Output:\")\nprint(initial_completion.content[:200])\n\ntry:\n    # Try to parse initial output\n    result = base_parser.parse(initial_completion.content)\n    print(\"\\n‚úÖ Initial parsing succeeded!\")\nexcept Exception as e:\n    print(f\"\\n‚ùå Initial parsing failed: {str(e)[:100]}\")\n    \n    # Use retry parser with the original prompt\n    print(\"\\nüîÑ Attempting retry with better instructions...\")\n    \n    result = retry_parser.parse_with_prompt(\n        initial_completion.content,\n        prompt_value=initial_prompt.format_prompt(text=financial_text)\n    )\n    \n    print(\"‚úÖ Retry succeeded!\")\n\n# **Display parsed result**\nprint(\"\\nüìä Parsed Financial Report:\")\nprint(f\"Company: {result.company_name} ({result.ticker})\")\nprint(f\"Revenue: ${result.revenue}M\")\nprint(f\"Profit Margin: {result.profit_margin*100:.1f}%\")\nprint(f\"YoY Growth: {result.year_over_year_growth*100:.1f}%\")\nprint(f\"Recommendation: {result.recommendation}\")\n\nprint(\"\\nüí° RetryParser adds format instructions and retries!\")\n```\n\n**Retry parser advantages:**\n- Automatic retry on failure\n- Better instructions on retry\n- Configurable retry attempts\n- Preserves original context\n\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## **Learner Activity 2: Practice Error Handling**\n\n**Practice Focus**: Implement robust parsing with error recovery\n\n### **Exercise 1: Build a Fault-Tolerant Parser**\n\n**Task**: Create a parser that handles various error conditions\n**Expected Output**: Reliable parsing despite errors"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# TODO: Create a parser that:\n",
    "# 1. Tries to parse normally\n",
    "# 2. Uses OutputFixingParser if that fails\n",
    "# 3. Falls back to a simpler structure if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Solution</summary>\n\n```python\nfrom langchain.output_parsers import OutputFixingParser\nfrom langchain_core.output_parsers import PydanticOutputParser\nfrom pydantic import BaseModel, Field\nfrom typing import Optional\n\n# **Define models with different complexity levels**\nclass DetailedProduct(BaseModel):\n    name: str\n    category: str\n    price: float\n    features: List[str]\n    specifications: Dict[str, str]\n    warranty_years: int\n\nclass SimpleProduct(BaseModel):\n    name: str\n    category: Optional[str] = None\n    price: Optional[float] = None\n    description: Optional[str] = None\n\ndef fault_tolerant_parse(text: str, llm):\n    \"\"\"Parse with multiple fallback levels\"\"\"\n    \n    # Level 1: Try detailed parsing\n    detailed_parser = PydanticOutputParser(pydantic_object=DetailedProduct)\n    \n    prompt1 = ChatPromptTemplate.from_template(\n        \"\"\"Extract detailed product information:\n        {text}\n        \n        {format_instructions}\n        \"\"\"\n    )\n    \n    try:\n        chain1 = prompt1 | llm | detailed_parser\n        result = chain1.invoke({\n            \"text\": text,\n            \"format_instructions\": detailed_parser.get_format_instructions()\n        })\n        print(\"‚úÖ Level 1: Detailed parsing succeeded\")\n        return result, \"detailed\"\n    except Exception as e:\n        print(f\"‚ö†Ô∏è Level 1 failed: {str(e)[:50]}\")\n    \n    # Level 2: Try with OutputFixingParser\n    fixing_parser = OutputFixingParser.from_llm(\n        parser=detailed_parser,\n        llm=llm\n    )\n    \n    try:\n        chain2 = prompt1 | llm | fixing_parser\n        result = chain2.invoke({\n            \"text\": text,\n            \"format_instructions\": detailed_parser.get_format_instructions()\n        })\n        print(\"‚úÖ Level 2: Fixing parser succeeded\")\n        return result, \"fixed\"\n    except Exception as e:\n        print(f\"‚ö†Ô∏è Level 2 failed: {str(e)[:50]}\")\n    \n    # Level 3: Fall back to simple structure\n    simple_parser = PydanticOutputParser(pydantic_object=SimpleProduct)\n    \n    prompt3 = ChatPromptTemplate.from_template(\n        \"\"\"Extract basic product information (name, category, price if available):\n        {text}\n        \n        {format_instructions}\n        \"\"\"\n    )\n    \n    try:\n        chain3 = prompt3 | llm | simple_parser\n        result = chain3.invoke({\n            \"text\": text,\n            \"format_instructions\": simple_parser.get_format_instructions()\n        })\n        print(\"‚úÖ Level 3: Simple parsing succeeded\")\n        return result, \"simple\"\n    except Exception as e:\n        print(f\"‚ùå All levels failed: {str(e)[:50]}\")\n        return None, \"failed\"\n\n# **Test with various inputs**\ntest_inputs = [\n    \"\"\"UltraPhone X: A premium smartphone in the electronics category for $999.\n    Features: 5G, OLED display, Triple camera, Face ID.\n    Specs: Screen 6.7\", Battery 4500mAh, Storage 256GB.\n    Comes with 2-year warranty.\"\"\",\n    \n    \"\"\"BasicWidget - Some kind of gadget that costs about fifty bucks\"\"\"\n]\n\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n\nprint(\"Fault-Tolerant Parsing Demo:\")\nprint(\"=\" * 50)\n\nfor i, text in enumerate(test_inputs, 1):\n    print(f\"\\nüìù Input {i}: {text[:50]}...\")\n    result, level = fault_tolerant_parse(text, llm)\n    \n    if result:\n        print(f\"\\nüìä Parsed at level: {level}\")\n        print(f\"  Product: {result.name}\")\n        if hasattr(result, 'features'):\n            print(f\"  Features: {len(result.features)} found\")\n        if hasattr(result, 'price') and result.price:\n            print(f\"  Price: ${result.price}\")\n\nprint(\"\\n‚úÖ Fault-tolerant parsing handles various input qualities!\")\n```\n\n**What you learned:**\n- Multi-level fallback strategy\n- Graceful degradation\n- Handling incomplete data\n- Robust error recovery\n\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## **Instructor Activity 3: Custom Parsers and Transformations**\n\n**Concept**: Create custom parsers for specific formats and transformations.\n\n### **Example 1: Custom Table Parser**\n\n**Problem**: Parse tabular data from text\n**Expected Output**: Structured table data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty cell for demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Solution</summary>\n\n```python\nfrom langchain_core.output_parsers import BaseOutputParser\nfrom typing import List, Dict\nimport pandas as pd\n\nclass TableOutputParser(BaseOutputParser[pd.DataFrame]):\n    \"\"\"Custom parser for table data\"\"\"\n    \n    def parse(self, text: str) -> pd.DataFrame:\n        \"\"\"Parse text into a pandas DataFrame\"\"\"\n        \n        lines = text.strip().split('\\n')\n        \n        # Find table boundaries (lines with | characters)\n        table_lines = [line for line in lines if '|' in line]\n        \n        if not table_lines:\n            raise ValueError(\"No table found in output\")\n        \n        # Parse header\n        header = [cell.strip() for cell in table_lines[0].split('|') if cell.strip()]\n        \n        # Skip separator line if present\n        data_start = 1\n        if len(table_lines) > 1 and all(c in '-|' for c in table_lines[1].replace(' ', '')):\n            data_start = 2\n        \n        # Parse data rows\n        data = []\n        for line in table_lines[data_start:]:\n            row = [cell.strip() for cell in line.split('|') if cell.strip()]\n            if len(row) == len(header):\n                data.append(row)\n        \n        # Create DataFrame\n        df = pd.DataFrame(data, columns=header)\n        \n        # Try to convert numeric columns\n        for col in df.columns:\n            try:\n                df[col] = pd.to_numeric(df[col])\n            except:\n                pass  # Keep as string\n        \n        return df\n    \n    def get_format_instructions(self) -> str:\n        return \"\"\"Format your response as a markdown table with | separators.\nExample:\n| Column1 | Column2 | Column3 |\n|---------|---------|----------|\n| Value1  | Value2  | Value3   |\n| Value4  | Value5  | Value6   |\"\"\"\n\n# **Use the custom parser**\ntable_parser = TableOutputParser()\n\nprompt = ChatPromptTemplate.from_template(\n    \"\"\"Create a comparison table for these items:\n    {items}\n    \n    Include columns for: Name, Category, Price, Rating, Availability\n    \n    {format_instructions}\n    \"\"\"\n)\n\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\nchain = prompt | llm | table_parser\n\n# **Test with product comparison**\nitems = \"\"\"Compare these laptops:\n1. MacBook Pro - Premium laptop, $2499, highly rated\n2. Dell XPS - Business laptop, $1599, good reviews\n3. HP Pavilion - Budget laptop, $699, decent for basics\n4. ThinkPad X1 - Business ultrabook, $1899, excellent keyboard\n\"\"\"\n\nresult = chain.invoke({\n    \"items\": items,\n    \"format_instructions\": table_parser.get_format_instructions()\n})\n\nprint(\"Custom Table Parser Result:\")\nprint(\"=\" * 50)\nprint(\"\\nüìä Parsed DataFrame:\")\nprint(result)\nprint(f\"\\nShape: {result.shape}\")\nprint(f\"Columns: {list(result.columns)}\")\nprint(f\"\\nData types:\")\nprint(result.dtypes)\n\n# **Perform DataFrame operations**\nif 'Price' in result.columns:\n    # Extract numeric price if formatted as $X,XXX\n    result['Price_Numeric'] = result['Price'].str.replace('$', '').str.replace(',', '').astype(float)\n    print(f\"\\nüí∞ Average Price: ${result['Price_Numeric'].mean():.2f}\")\n    print(f\"Price Range: ${result['Price_Numeric'].min():.2f} - ${result['Price_Numeric'].max():.2f}\")\n\nprint(\"\\n‚úÖ Custom parser converts text to pandas DataFrame!\")\n```\n\n**Custom parser benefits:**\n- Parse specific formats\n- Direct to pandas DataFrame\n- Custom validation logic\n- Type conversion\n\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## **Summary & Next Steps**\n\n### **What You've Learned**\n‚úÖ Advanced Pydantic models with nested structures and validation  \n‚úÖ Handling optional fields and union types  \n‚úÖ Error recovery with OutputFixingParser and RetryParser  \n‚úÖ Custom parsers for specific formats  \n‚úÖ Table parsing and DataFrame conversion  \n‚úÖ Multi-level fallback strategies  \n\n### **Key Takeaways**\n1. **Pydantic provides powerful validation** - Use validators for business logic\n2. **Handle errors gracefully** - Multiple fallback levels ensure reliability\n3. **Custom parsers for custom formats** - Build parsers for your specific needs\n4. **Union types handle variability** - Parse different data shapes safely\n5. **Tables to DataFrames** - Convert text tables for analysis\n\n### **What's Next?**\nIn the next notebook (`05_document_loading.ipynb`), you'll learn:\n- Loading documents from various sources\n- Text splitting strategies\n- Metadata extraction\n- Handling different file formats\n- Preprocessing for embeddings\n\n### **Resources**\n- [LangChain Output Parsers](https://python.langchain.com/docs/modules/model_io/output_parsers/)\n- [Pydantic Documentation](https://docs.pydantic.dev/)\n- [JSON Schema](https://json-schema.org/)\n- [Pandas Documentation](https://pandas.pydata.org/docs/)\n\n---\n\nüéâ **Congratulations!** You've mastered advanced output parsing! You can now extract and validate complex structured data from LLM outputs."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}