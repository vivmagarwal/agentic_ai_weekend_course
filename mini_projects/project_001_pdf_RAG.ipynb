{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "id": "abR3o8iXq4Nv"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain-community langchain-openai langchain-core langchain-tavily faiss-cpu pymupdf -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OPENAI API KEY: \")\n",
        "os.environ[\"TAVILY_API_KEY\"] = getpass(\"Enter TAVILY API KEY: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJJBzh99rj77",
        "outputId": "157b94ff-534c-4754-88b4-c321a7374f9a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OPENAI API KEY: ··········\n",
            "Enter TAVILY API KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "# upload the pdf file\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "# get the file path and store in temporary location\n",
        "file_path = os.path.join(tempfile.gettempdir(), file_name)\n",
        "with open(file_path, \"wb\") as f:\n",
        "        f.write(uploaded[file_name])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "W5FDIFsArs4Y",
        "outputId": "0a1d06de-aea9-436a-a78a-70117cc1acda"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-45fb1026-cf85-4533-941e-7015f45fa165\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-45fb1026-cf85-4533-941e-7015f45fa165\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ToK guide.pdf to ToK guide (1).pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_tavily import TavilySearch\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
        "llm = ChatOpenAI(model=\"gpt-5-mini-2025-08-07\", temperature=0)\n",
        "tool = TavilySearch(max_results=3, topic=\"general\")\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)"
      ],
      "metadata": {
        "id": "JKiuR7F0sG-3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "gdUGEVOtsJRy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "answer_determination_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are an AI assistant tasked with determining if the provided context from a PDF contains sufficient information to answer a user's question.\n",
        "\n",
        "Context from PDF: {context}\n",
        "\n",
        "User Question: {question}\n",
        "\n",
        "First, carefully analyze if the context provides adequate information to answer the question.\n",
        "\n",
        "If the context contains sufficient information to answer the question, respond with a complete and accurate answer based ONLY on the provided context.\n",
        "\n",
        "If the context does NOT contain sufficient information to fully answer the question, respond with exactly: \"[NEED_WEB_SEARCH]\"\n",
        "\n",
        "Your response:\n",
        "\"\"\")\n",
        "\n",
        "web_search_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are an AI assistant helping a user with their question.\n",
        "\n",
        "User Question: {question}\n",
        "\n",
        "Web Search Results: {web_results}\n",
        "\n",
        "Using the web search results, provide a comprehensive and accurate answer to the user's question.\n",
        "Make sure to cite sources from the search results where appropriate.\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "9prtxFr_sTaa"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# --- PDF Processing Function ---\n",
        "def process_pdf(file_path):\n",
        "    loader = PyMuPDFLoader(file_path)\n",
        "    docs = loader.load()\n",
        "    chunks = text_splitter.split_documents(docs)\n",
        "    vector_store = FAISS.from_documents(chunks, embedding_model)\n",
        "    return vector_store"
      ],
      "metadata": {
        "id": "FkUorpuHsla9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = process_pdf(file_path)"
      ],
      "metadata": {
        "id": "b65W7KzNsqKI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})"
      ],
      "metadata": {
        "id": "_BQ6T1b4sZ82"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "determination_chain = (\n",
        "  {\n",
        "    \"context\": retriever | format_docs,\n",
        "    \"question\": RunnablePassthrough(),\n",
        "  }\n",
        "  | answer_determination_prompt\n",
        "  | llm\n",
        "  | StrOutputParser()\n",
        ")\n",
        "\n",
        "web_search_chain = (\n",
        "  {\n",
        "    \"question\": RunnablePassthrough(),\n",
        "    \"web_results\": lambda x: tool.invoke({\"query\": x})\n",
        "  }\n",
        "  | web_search_prompt\n",
        "  | llm\n",
        "  | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "MGkfdIfHscCb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def agent(question):\n",
        "  pdf_response = determination_chain.invoke(question)\n",
        "  if \"[NEED_WEB_SEARCH]\" in pdf_response:\n",
        "    print(\"\\n\\u2139\\ufe0f Info not found in PDF. Searching the web...\")\n",
        "    return web_search_chain.invoke(question)\n",
        "  else:\n",
        "    return pdf_response"
      ],
      "metadata": {
        "id": "TuU2DDHdtgqb"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask questions interactively\n",
        "while True:\n",
        "  query = input(\"\\nAsk a question about your PDF (or type 'exit'): \")\n",
        "  if query.lower() == 'exit':\n",
        "    break\n",
        "  answer = agent(query)\n",
        "  print(\"\\n✉️ Answer:\", answer)"
      ],
      "metadata": {
        "id": "L7g2scKvtKCp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c8cfb7d7-3c65-414f-c22d-367a13ebd0c1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✉️ Answer: The document is the International Baccalaureate (IB) Diploma Programme Theory of Knowledge (TOK) guide. It is intended to guide the planning, teaching and assessment of the DP TOK course, with TOK teachers as the primary audience (and also to inform students and parents). It sits within the DP core, aligns with the IB mission, and is available via the programme resource centre for first assessment in 2022.\n",
            "\n",
            "✉️ Answer: The 12 TOK concepts are: evidence, certainty, truth, interpretation, power, justification, explanation, objectivity, perspective, culture, values, and responsibility.\n",
            "\n",
            "ℹ️ Info not found in PDF. Searching the web...\n",
            "\n",
            "✉️ Answer: Brief answer\n",
            "- In IB DP Theory of Knowledge (TOK), \"evidence\" is a central concept used to evaluate knowledge claims: what counts as evidence, how strong it is, how it supports or undermines claims, and how it varies across Areas of Knowledge (AOKs) and Ways of Knowing (WOKs). (See TOK overview: IBO) (See TOK resources: Blen).  \n",
            "\n",
            "What the IBO and TOK guidance say\n",
            "- TOK asks students to be critical about knowledge itself — including the nature, use and limits of evidence when justifying claims. The subject places emphasis on evaluating evidence rather than simply accepting claims at face value. (IBO TOK summary)  \n",
            "- Many TOK resources list \"evidence\" as one of the core evaluative concepts students must master, alongside concepts such as causation and significance. (Blen: \"Critical Concepts for your IBDP TOK\")  \n",
            "\n",
            "What \"evidence\" can mean in TOK\n",
            "- Evidence is any information or reason used to support a knowledge claim. Its form and standards vary by AOK and WOK. Types include:\n",
            "  - Empirical/data evidence (measurements, controlled experiments, statistics) — common in the natural sciences and human sciences.\n",
            "  - Logical/mathematical proof — in mathematics, evidence is deductive proof rather than empirical support.\n",
            "  - Historical sources — primary documents, eyewitness testimony, archaeological finds; issues of provenance, context and bias are key.\n",
            "  - Testimony and authority — expert reports, interviews, eyewitness accounts (raises questions of reliability and trust).\n",
            "  - Introspection and perception — senses and memory provide evidence but can be fallible.\n",
            "  - Artistic/interpretive evidence — stylistic features, context and audience responses support claims about meaning in the arts.\n",
            "  - Ethical/moral intuitions and thought experiments — used in ethics but evaluated differently than empirical data.\n",
            "\n",
            "Key TOK questions about evidence\n",
            "- What kinds of evidence count as good evidence in this AOK?\n",
            "- How reliable, sufficient and relevant is a given piece of evidence?\n",
            "- To what extent does evidence justify a knowledge claim (proof vs support)?\n",
            "- How do our WOKs (perception, reason, emotion, language, memory, imagination, faith, intuition) shape, limit or bias evidence?\n",
            "- When does correlation become causation, and how do we detect bias, error or selective use of evidence?\n",
            "\n",
            "How evidence differs across AOKs (short examples)\n",
            "- Natural sciences: reproducibility, controlled methods, statistical significance, peer review.\n",
            "- Mathematics: formal proof; a counterexample can disprove a claim.\n",
            "- History: corroboration between sources, understanding context and perspective, dealing with incomplete records.\n",
            "- Human sciences: sampling, operational definitions, ethical constraints; distinguishing correlation from causation.\n",
            "- Ethics: thought experiments and rational argument are evidence for moral reasoning but rely on shared values.\n",
            "- The arts: evidence is often interpretive and persuasive rather than conclusive.\n",
            "\n",
            "Common TOK pitfalls about evidence\n",
            "- Confusing anecdote with representative evidence.\n",
            "- Treating correlation as causation without checking mechanism or controls.\n",
            "- Assuming consensus = truth (consensus can be mistaken or socially driven).\n",
            "- Ignoring limitations, bias and context of sources.\n",
            "- Failing to question the methods used to produce evidence.\n",
            "\n",
            "How to use \"evidence\" effectively in TOK assessments\n",
            "- Link evidence explicitly to a knowledge claim and to a knowledge question (KQ). Explain how it supports or undermines the claim.\n",
            "- Evaluate the quality of the evidence: source, method, scope, reliability, replicability, possible bias and alternative interpretations.\n",
            "- Present balanced analysis: give counterclaims and show how different evidence or different interpretations change conclusions.\n",
            "- Bring in WOKs/AOKs to explain why evidence is accepted in one context but not in another.\n",
            "- Use real, specific examples (case studies, experiments, historical documents, statistics) and analyze their strengths and weaknesses.\n",
            "\n",
            "Practical student checklist for evaluating a piece of evidence\n",
            "- What is the origin of the evidence? (who, when, how)\n",
            "- Is the method transparent and appropriate to the claim?\n",
            "- Could the evidence be biased, incomplete, or misinterpreted?\n",
            "- Is it corroborated by independent sources?\n",
            "- Is it sufficient to justify the claim, or does it only suggest a possibility?\n",
            "- How do relevant WOKs influence its reliability?\n",
            "\n",
            "Sample TOK knowledge questions about evidence\n",
            "- \"To what extent can empirical evidence in the human sciences justify general claims about human behaviour?\"  \n",
            "- \"How does the notion of proof in mathematics differ from evidence in the natural sciences?\"  \n",
            "- \"When is testimonial evidence more reliable than experimental data?\"\n",
            "\n",
            "Sources and further reading\n",
            "- IBO. RESEARCH SUMMARY — Theory of knowledge (TOK). IB discussion of TOK’s aims and central elements (see IBO TOK summary PDF). https://ibo.org/contentassets/d74675437b4f4ab38312702599a432f1/toksummaryengweb.pdf  \n",
            "- \"Critical Concepts for your IBDP TOK | Explained\" — overview noting evidence as a core TOK concept and one of the evaluative criteria (with causation and significance). https://helloblen.com/blog/3258-critical-concepts-for-your-ibdp-tok-explained  \n",
            "- Introductory TOK guides (e.g., AscendNow) emphasize questioning assumptions and evaluating evidence across contexts. https://ascendnow.org/guides/theory-of-knowledge-in-ibdb/\n",
            "\n",
            "If you want, I can:\n",
            "- Draft a short TOK essay plan that focuses on evidence (with a possible prescribed title), or\n",
            "- Create a list of flashcards with example pieces of evidence and how to evaluate them for different AOKs. Which would help you most?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4158159831.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Ask questions interactively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nAsk a question about your PDF (or type 'exit'): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}