{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a87c73",
   "metadata": {},
   "source": [
    "# 09 - Memory and Conversations: Building Stateful AI Applications\n",
    "\n",
    "## Overview\n",
    "In this notebook, we'll learn how to add memory to LLM applications, enabling them to maintain context across interactions. You'll build chatbots that remember previous conversations, track entities, and maintain long-term knowledge.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this notebook, you will be able to:\n",
    "- Implement different types of conversation memory\n",
    "- Build chatbots with context awareness\n",
    "- Use entity memory to track specific information\n",
    "- Create summary-based memory for long conversations\n",
    "- Implement knowledge graph memory\n",
    "- Design persistent memory systems\n",
    "\n",
    "## Prerequisites\n",
    "- Completion of notebooks 01-08\n",
    "- Understanding of chains and agents\n",
    "- Basic knowledge of conversation design\n",
    "\n",
    "## Back-and-Forth Teaching Pattern\n",
    "This notebook follows our pattern:\n",
    "1. **Instructor Activity**: Demonstrates a concept with complete examples\n",
    "2. **Learner Activity**: You apply the concept with guidance and hidden solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's install and import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install langchain langchain-community langchain-openai redis faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any, Optional\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import (\n",
    "    ConversationBufferMemory,\n",
    "    ConversationSummaryMemory,\n",
    "    ConversationBufferWindowMemory,\n",
    "    ConversationEntityMemory,\n",
    "    ConversationKGMemory,\n",
    "    CombinedMemory,\n",
    "    VectorStoreRetrieverMemory\n",
    ")\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import ConversationChain, LLMChain\n",
    "from langchain.schema import HumanMessage, AIMessage, BaseMessage\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructor_1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Instructor Activity 1: Basic Conversation Memory Types\n",
    "\n",
    "Let's explore different types of memory for conversations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buffer_memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Conversation Buffer Memory - Stores all messages\n",
    "llm = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "# Create buffer memory\n",
    "buffer_memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "# Create conversation chain\n",
    "conversation_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant having a conversation with a human.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=buffer_memory,\n",
    "    prompt=conversation_prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Have a conversation\n",
    "print(\"Buffer Memory Conversation:\\n\")\n",
    "response1 = conversation.predict(input=\"Hi! My name is Alice and I love programming.\")\n",
    "print(f\"AI: {response1}\\n\")\n",
    "\n",
    "response2 = conversation.predict(input=\"What's my name?\")\n",
    "print(f\"AI: {response2}\\n\")\n",
    "\n",
    "response3 = conversation.predict(input=\"What did I tell you I love?\")\n",
    "print(f\"AI: {response3}\\n\")\n",
    "\n",
    "# Check memory contents\n",
    "print(\"\\nMemory Contents:\")\n",
    "print(buffer_memory.chat_memory.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "window_memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Conversation Buffer Window Memory - Keeps only last K messages\n",
    "\n",
    "window_memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    k=2  # Keep only last 2 exchanges\n",
    ")\n",
    "\n",
    "window_conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=window_memory,\n",
    "    prompt=conversation_prompt,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"Window Memory Conversation (k=2):\\n\")\n",
    "\n",
    "# Have a longer conversation\n",
    "messages = [\n",
    "    \"Hi! I'm Bob and I'm from New York.\",\n",
    "    \"I work as a data scientist.\",\n",
    "    \"My favorite color is blue.\",\n",
    "    \"What's my name?\",  # Should remember (within window)\n",
    "    \"Where am I from?\"   # Might not remember (outside window)\n",
    "]\n",
    "\n",
    "for msg in messages:\n",
    "    print(f\"Human: {msg}\")\n",
    "    response = window_conversation.predict(input=msg)\n",
    "    print(f\"AI: {response}\\n\")\n",
    "\n",
    "print(\"\\nWindow Memory Contents (only last 2 exchanges):\")\n",
    "print(window_memory.chat_memory.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary_memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Conversation Summary Memory - Stores summarized conversation\n",
    "\n",
    "summary_memory = ConversationSummaryMemory(\n",
    "    llm=llm,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=False\n",
    ")\n",
    "\n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"The following is a friendly conversation between a human and an AI.\n",
    "    The AI is talkative and provides lots of specific details from its context.\n",
    "    \n",
    "    Current conversation summary:\n",
    "    {chat_history}\n",
    "    \n",
    "    Human: {input}\n",
    "    AI:\"\"\"\n",
    ")\n",
    "\n",
    "summary_conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=summary_memory,\n",
    "    prompt=summary_prompt,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"Summary Memory Conversation:\\n\")\n",
    "\n",
    "# Have a detailed conversation\n",
    "detailed_messages = [\n",
    "    \"I'm planning a trip to Japan next month. I'm really excited about it!\",\n",
    "    \"I want to visit Tokyo, Kyoto, and Osaka. Any recommendations?\",\n",
    "    \"I'm particularly interested in temples, technology, and food.\",\n",
    "    \"What should I know about Japanese etiquette?\"\n",
    "]\n",
    "\n",
    "for msg in detailed_messages:\n",
    "    print(f\"Human: {msg}\")\n",
    "    response = summary_conversation.predict(input=msg)\n",
    "    print(f\"AI: {response[:200]}...\\n\")  # Truncate for display\n",
    "\n",
    "print(\"\\nSummary Memory Contents:\")\n",
    "print(f\"Summary: {summary_memory.buffer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entity_memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Conversation Entity Memory - Tracks entities mentioned\n",
    "\n",
    "entity_memory = ConversationEntityMemory(\n",
    "    llm=llm,\n",
    "    memory_key=\"entities\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "entity_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are having a conversation with a human.\n",
    "    You remember specific facts about entities mentioned.\n",
    "    \n",
    "    Relevant entity information:\n",
    "    {entities}\n",
    "    \n",
    "    Conversation history:\n",
    "    {history}\n",
    "    \n",
    "    Human: {input}\n",
    "    AI:\"\"\"\n",
    ")\n",
    "\n",
    "# Manual chain with entity memory\n",
    "def entity_conversation(human_input: str) -> str:\n",
    "    # Get entity information\n",
    "    entities_info = entity_memory.load_memory_variables({\"input\": human_input})\n",
    "    \n",
    "    # Get conversation history\n",
    "    history = entity_memory.chat_memory.messages\n",
    "    \n",
    "    # Format and get response\n",
    "    formatted_prompt = entity_prompt.format(\n",
    "        entities=entities_info.get(\"entities\", \"\"),\n",
    "        history=history,\n",
    "        input=human_input\n",
    "    )\n",
    "    \n",
    "    response = llm.predict(formatted_prompt)\n",
    "    \n",
    "    # Save to memory\n",
    "    entity_memory.save_context({\"input\": human_input}, {\"output\": response})\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"Entity Memory Conversation:\\n\")\n",
    "\n",
    "# Conversation with multiple entities\n",
    "entity_messages = [\n",
    "    \"I'm Sarah and I work at Google as a software engineer.\",\n",
    "    \"My colleague John works in the marketing department at Microsoft.\",\n",
    "    \"Tell me what you know about Sarah.\",\n",
    "    \"What about John?\"\n",
    "]\n",
    "\n",
    "for msg in entity_messages:\n",
    "    print(f\"Human: {msg}\")\n",
    "    response = entity_conversation(msg)\n",
    "    print(f\"AI: {response}\\n\")\n",
    "\n",
    "print(\"\\nEntity Store:\")\n",
    "print(entity_memory.entity_store.store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined_memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Combined Memory - Use multiple memory types together\n",
    "\n",
    "from langchain.memory import CombinedMemory\n",
    "\n",
    "# Create individual memories\n",
    "conv_memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    input_key=\"input\",\n",
    "    k=3\n",
    ")\n",
    "\n",
    "summary_memory_2 = ConversationSummaryMemory(\n",
    "    llm=llm,\n",
    "    memory_key=\"summary\",\n",
    "    input_key=\"input\"\n",
    ")\n",
    "\n",
    "# Combine memories\n",
    "combined_memory = CombinedMemory(memories=[conv_memory, summary_memory_2])\n",
    "\n",
    "combined_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a helpful assistant with access to both recent messages and conversation summary.\n",
    "    \n",
    "    Overall Summary:\n",
    "    {summary}\n",
    "    \n",
    "    Recent Messages:\n",
    "    {chat_history}\n",
    "    \n",
    "    Human: {input}\n",
    "    AI:\"\"\"\n",
    ")\n",
    "\n",
    "combined_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=combined_prompt,\n",
    "    memory=combined_memory,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"Combined Memory Conversation:\\n\")\n",
    "\n",
    "combined_messages = [\n",
    "    \"I'm learning about machine learning and deep learning.\",\n",
    "    \"I started with linear regression and decision trees.\",\n",
    "    \"Now I'm studying neural networks and transformers.\",\n",
    "    \"What topics have I covered so far?\"\n",
    "]\n",
    "\n",
    "for msg in combined_messages:\n",
    "    print(f\"Human: {msg}\")\n",
    "    response = combined_chain.predict(input=msg)\n",
    "    print(f\"AI: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "learner_1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Learner Activity 1: Build a Personal Assistant with Memory\n",
    "\n",
    "Create a personal assistant that remembers user preferences, tasks, and important information.\n",
    "\n",
    "**Task**: Build an assistant that:\n",
    "1. Remembers user preferences (name, interests, goals)\  \n",
    "2. Tracks tasks and reminders across conversations\n",
    "3. Maintains a summary of long-term interactions\n",
    "4. Can recall specific information when asked\n",
    "5. Adapts responses based on user history\n",
    "\n",
    "Requirements:\n",
    "- Use at least 2 different memory types\n",
    "- Implement preference tracking\n",
    "- Add task management with memory\n",
    "- Handle context switching gracefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "learner_1_starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your personal assistant with memory\n",
    "\n",
    "class PersonalAssistant:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0.7)\n",
    "        # TODO: Initialize different memory types\n",
    "        # - Buffer memory for recent conversation\n",
    "        # - Entity memory for user preferences\n",
    "        # - Custom memory for tasks\n",
    "        \n",
    "        # Your initialization here\n",
    "        pass\n",
    "    \n",
    "    def remember_preference(self, preference: str, value: str):\n",
    "        \"\"\"Store user preferences.\"\"\"\n",
    "        # TODO: Implement preference storage\n",
    "        pass\n",
    "    \n",
    "    def add_task(self, task: str, due_date: Optional[str] = None):\n",
    "        \"\"\"Add a task to memory.\"\"\"\n",
    "        # TODO: Implement task storage\n",
    "        pass\n",
    "    \n",
    "    def get_tasks(self) -> List[str]:\n",
    "        \"\"\"Retrieve all tasks.\"\"\"\n",
    "        # TODO: Implement task retrieval\n",
    "        pass\n",
    "    \n",
    "    def chat(self, user_input: str) -> str:\n",
    "        \"\"\"Main conversation interface.\"\"\"\n",
    "        # TODO: Implement chat with memory\n",
    "        # - Check for task-related requests\n",
    "        # - Use appropriate memory\n",
    "        # - Generate contextual response\n",
    "        pass\n",
    "\n",
    "# TODO: Test your assistant\n",
    "# assistant = PersonalAssistant()\n",
    "# Test conversations with preferences, tasks, and memory recall\n",
    "\n",
    "# Your test code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "learner_1_solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution (hidden by default)\n",
    "\n",
    "\"\"\"\n",
    "class PersonalAssistant:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0.7)\n",
    "        \n",
    "        # Recent conversation memory\n",
    "        self.conversation_memory = ConversationBufferWindowMemory(\n",
    "            memory_key=\"recent_chat\",\n",
    "            return_messages=True,\n",
    "            k=5\n",
    "        )\n",
    "        \n",
    "        # Entity memory for user info\n",
    "        self.entity_memory = ConversationEntityMemory(\n",
    "            llm=self.llm,\n",
    "            memory_key=\"entities\",\n",
    "            return_messages=False\n",
    "        )\n",
    "        \n",
    "        # Summary memory for long-term\n",
    "        self.summary_memory = ConversationSummaryMemory(\n",
    "            llm=self.llm,\n",
    "            memory_key=\"long_term_summary\",\n",
    "            return_messages=False\n",
    "        )\n",
    "        \n",
    "        # Custom storage for preferences and tasks\n",
    "        self.preferences = {}\n",
    "        self.tasks = []\n",
    "        self.interaction_count = 0\n",
    "        \n",
    "        # Create main prompt\n",
    "        self.prompt = ChatPromptTemplate.from_template(\n",
    "            '''You are a personal assistant who remembers everything about the user.\n",
    "            \n",
    "            User Preferences:\n",
    "            {preferences}\n",
    "            \n",
    "            Current Tasks:\n",
    "            {tasks}\n",
    "            \n",
    "            Known Entities:\n",
    "            {entities}\n",
    "            \n",
    "            Long-term Summary:\n",
    "            {long_term_summary}\n",
    "            \n",
    "            Recent Conversation:\n",
    "            {recent_chat}\n",
    "            \n",
    "            Human: {input}\n",
    "            \n",
    "            Assistant (be personal and reference their history when relevant):'''\n",
    "        )\n",
    "    \n",
    "    def remember_preference(self, category: str, value: str):\n",
    "        '''Store user preferences.'''\n",
    "        if category not in self.preferences:\n",
    "            self.preferences[category] = []\n",
    "        self.preferences[category].append(value)\n",
    "        \n",
    "        # Also save to entity memory\n",
    "        self.entity_memory.save_context(\n",
    "            {\"input\": f\"User preference - {category}: {value}\"},\n",
    "            {\"output\": f\"Noted your {category} preference: {value}\"}\n",
    "        )\n",
    "        \n",
    "        return f\"Preference saved: {category} = {value}\"\n",
    "    \n",
    "    def add_task(self, task: str, due_date: Optional[str] = None):\n",
    "        '''Add a task to memory.'''\n",
    "        task_obj = {\n",
    "            \"task\": task,\n",
    "            \"due_date\": due_date or \"No deadline\",\n",
    "            \"created\": datetime.now().isoformat(),\n",
    "            \"status\": \"pending\"\n",
    "        }\n",
    "        self.tasks.append(task_obj)\n",
    "        return f\"Task added: {task} (Due: {due_date or 'No deadline'})\"\n",
    "    \n",
    "    def complete_task(self, task_index: int):\n",
    "        '''Mark a task as complete.'''\n",
    "        if 0 <= task_index < len(self.tasks):\n",
    "            self.tasks[task_index][\"status\"] = \"completed\"\n",
    "            return f\"Task completed: {self.tasks[task_index]['task']}\"\n",
    "        return \"Invalid task index\"\n",
    "    \n",
    "    def get_tasks(self, status: str = \"pending\") -> List[Dict]:\n",
    "        '''Retrieve tasks by status.'''\n",
    "        return [t for t in self.tasks if t[\"status\"] == status]\n",
    "    \n",
    "    def _format_preferences(self) -> str:\n",
    "        '''Format preferences for prompt.'''\n",
    "        if not self.preferences:\n",
    "            return \"No preferences stored yet\"\n",
    "        \n",
    "        formatted = []\n",
    "        for category, values in self.preferences.items():\n",
    "            formatted.append(f\"{category}: {', '.join(values)}\")\n",
    "        return \"\\n\".join(formatted)\n",
    "    \n",
    "    def _format_tasks(self) -> str:\n",
    "        '''Format tasks for prompt.'''\n",
    "        pending = self.get_tasks(\"pending\")\n",
    "        if not pending:\n",
    "            return \"No pending tasks\"\n",
    "        \n",
    "        formatted = []\n",
    "        for i, task in enumerate(pending):\n",
    "            formatted.append(f\"{i+1}. {task['task']} (Due: {task['due_date']})\")\n",
    "        return \"\\n\".join(formatted)\n",
    "    \n",
    "    def chat(self, user_input: str) -> str:\n",
    "        '''Main conversation interface.'''\n",
    "        self.interaction_count += 1\n",
    "        \n",
    "        # Check for task commands\n",
    "        if \"add task\" in user_input.lower():\n",
    "            # Extract task from input\n",
    "            task_text = user_input.replace(\"add task\", \"\").replace(\"Add task\", \"\").strip()\n",
    "            self.add_task(task_text)\n",
    "            user_input += \" [Task added to memory]\"\n",
    "        \n",
    "        # Check for preference setting\n",
    "        if \"my favorite\" in user_input.lower() or \"i prefer\" in user_input.lower():\n",
    "            # Simple extraction (in production, use NLP)\n",
    "            if \"favorite\" in user_input:\n",
    "                parts = user_input.split(\"favorite\")\n",
    "                if len(parts) > 1:\n",
    "                    pref_text = parts[1].strip()\n",
    "                    # Extract first few words as preference\n",
    "                    words = pref_text.split()[:3]\n",
    "                    if words:\n",
    "                        category = words[0]\n",
    "                        value = ' '.join(words[1:]) if len(words) > 1 else \"noted\"\n",
    "                        self.remember_preference(category, value)\n",
    "        \n",
    "        # Load all memory variables\n",
    "        recent_chat = self.conversation_memory.load_memory_variables({})\n",
    "        entities = self.entity_memory.load_memory_variables({\"input\": user_input})\n",
    "        summary = self.summary_memory.load_memory_variables({})\n",
    "        \n",
    "        # Format prompt\n",
    "        formatted_prompt = self.prompt.format(\n",
    "            preferences=self._format_preferences(),\n",
    "            tasks=self._format_tasks(),\n",
    "            entities=entities.get(\"entities\", \"\"),\n",
    "            long_term_summary=summary.get(\"long_term_summary\", \"\"),\n",
    "            recent_chat=recent_chat.get(\"recent_chat\", []),\n",
    "            input=user_input\n",
    "        )\n",
    "        \n",
    "        # Get response\n",
    "        response = self.llm.predict(formatted_prompt)\n",
    "        \n",
    "        # Save to memories\n",
    "        context = {\"input\": user_input}\n",
    "        output_dict = {\"output\": response}\n",
    "        \n",
    "        self.conversation_memory.save_context(context, output_dict)\n",
    "        self.entity_memory.save_context(context, output_dict)\n",
    "        self.summary_memory.save_context(context, output_dict)\n",
    "        \n",
    "        return response\n",
    "\n",
    "# Test the personal assistant\n",
    "print(\"Personal Assistant with Memory Demo\\n\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "assistant = PersonalAssistant()\n",
    "\n",
    "# Test conversation\n",
    "test_messages = [\n",
    "    \"Hi! I'm Alex and I love hiking and photography.\",\n",
    "    \"My favorite color is green and I'm learning Python.\",\n",
    "    \"Add task: Complete the machine learning course by next Friday\",\n",
    "    \"Add task: Buy a new camera lens\",\n",
    "    \"What do you remember about me?\",\n",
    "    \"What tasks do I have?\",\n",
    "    \"I just finished my Python project!\",\n",
    "    \"Can you remind me of my interests?\"\n",
    "]\n",
    "\n",
    "for msg in test_messages:\n",
    "    print(f\"\\nUser: {msg}\")\n",
    "    response = assistant.chat(msg)\n",
    "    print(f\"Assistant: {response}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nStored Preferences:\")\n",
    "print(assistant.preferences)\n",
    "\n",
    "print(\"\\nPending Tasks:\")\n",
    "for task in assistant.get_tasks():\n",
    "    print(f\"- {task['task']} (Due: {task['due_date']})\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Create a personal assistant with comprehensive memory!\")\n",
    "print(\"The solution combines multiple memory types for a rich conversational experience.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructor_2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Instructor Activity 2: Advanced Memory Patterns\n",
    "\n",
    "Let's explore more sophisticated memory patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vector_memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Store Memory - Semantic search over conversation history\n",
    "\n",
    "# Create embeddings and vector store\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Create an empty vector store\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"Initial memory\"],  # Need at least one item to initialize\n",
    "    embeddings\n",
    ")\n",
    "\n",
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# Create vector store memory\n",
    "vector_memory = VectorStoreRetrieverMemory(\n",
    "    retriever=retriever,\n",
    "    memory_key=\"relevant_history\",\n",
    "    return_docs=True\n",
    ")\n",
    "\n",
    "# Custom chain with vector memory\n",
    "class SemanticMemoryChat:\n",
    "    def __init__(self, vector_memory, llm):\n",
    "        self.vector_memory = vector_memory\n",
    "        self.llm = llm\n",
    "        self.all_messages = []  # Keep all messages for adding to vector store\n",
    "    \n",
    "    def chat(self, user_input: str) -> str:\n",
    "        # Search for relevant history\n",
    "        relevant_docs = self.vector_memory.retriever.get_relevant_documents(user_input)\n",
    "        \n",
    "        # Format relevant history\n",
    "        relevant_history = \"\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "        \n",
    "        # Create prompt with relevant history\n",
    "        prompt = f\"\"\"You are a helpful assistant. Use relevant conversation history to provide context.\n",
    "        \n",
    "        Relevant History:\n",
    "        {relevant_history}\n",
    "        \n",
    "        Current Input: {user_input}\n",
    "        \n",
    "        Response:\"\"\"\n",
    "        \n",
    "        # Get response\n",
    "        response = self.llm.predict(prompt)\n",
    "        \n",
    "        # Save to vector store\n",
    "        exchange = f\"Human: {user_input}\\nAI: {response}\"\n",
    "        self.all_messages.append(exchange)\n",
    "        \n",
    "        # Add to vector store (in production, batch this)\n",
    "        self.vector_memory.retriever.vectorstore.add_texts([exchange])\n",
    "        \n",
    "        return response\n",
    "\n",
    "# Test semantic memory\n",
    "semantic_chat = SemanticMemoryChat(vector_memory, llm)\n",
    "\n",
    "print(\"Semantic Memory Chat:\\n\")\n",
    "\n",
    "# Have a conversation with various topics\n",
    "semantic_messages = [\n",
    "    \"I'm interested in learning about space exploration.\",\n",
    "    \"Tell me about the Mars rovers.\",\n",
    "    \"Let's switch topics. What's your take on artificial intelligence?\",\n",
    "    \"How does machine learning work?\",\n",
    "    \"Going back to our earlier topic, what's the future of space exploration?\"  # Should recall space context\n",
    "]\n",
    "\n",
    "for msg in semantic_messages:\n",
    "    print(f\"Human: {msg}\")\n",
    "    response = semantic_chat.chat(msg)\n",
    "    print(f\"AI: {response[:200]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent_memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persistent Memory with JSON storage\n",
    "\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "class PersistentMemory:\n",
    "    \"\"\"Memory that persists across sessions.\"\"\"\n",
    "    \n",
    "    def __init__(self, file_path: str = \"conversation_memory.json\"):\n",
    "        self.file_path = file_path\n",
    "        self.memory = self._load_memory()\n",
    "        self.llm = ChatOpenAI(temperature=0.7)\n",
    "    \n",
    "    def _load_memory(self) -> Dict:\n",
    "        \"\"\"Load memory from file.\"\"\"\n",
    "        if os.path.exists(self.file_path):\n",
    "            with open(self.file_path, 'r') as f:\n",
    "                return json.load(f)\n",
    "        return {\n",
    "            \"conversations\": [],\n",
    "            \"user_profile\": {},\n",
    "            \"topics_discussed\": [],\n",
    "            \"important_facts\": [],\n",
    "            \"session_count\": 0\n",
    "        }\n",
    "    \n",
    "    def _save_memory(self):\n",
    "        \"\"\"Save memory to file.\"\"\"\n",
    "        with open(self.file_path, 'w') as f:\n",
    "            json.dump(self.memory, f, indent=2)\n",
    "    \n",
    "    def start_session(self):\n",
    "        \"\"\"Start a new conversation session.\"\"\"\n",
    "        self.memory[\"session_count\"] += 1\n",
    "        self.current_session = []\n",
    "        return f\"Session {self.memory['session_count']} started. Welcome back!\"\n",
    "    \n",
    "    def update_profile(self, key: str, value: Any):\n",
    "        \"\"\"Update user profile information.\"\"\"\n",
    "        self.memory[\"user_profile\"][key] = value\n",
    "        self._save_memory()\n",
    "    \n",
    "    def add_important_fact(self, fact: str):\n",
    "        \"\"\"Mark something as important to remember.\"\"\"\n",
    "        fact_entry = {\n",
    "            \"fact\": fact,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"session\": self.memory[\"session_count\"]\n",
    "        }\n",
    "        self.memory[\"important_facts\"].append(fact_entry)\n",
    "        self._save_memory()\n",
    "    \n",
    "    def chat(self, user_input: str) -> str:\n",
    "        \"\"\"Chat with persistent memory.\"\"\"\n",
    "        # Check for profile updates\n",
    "        if \"my name is\" in user_input.lower():\n",
    "            # Extract name (simple approach)\n",
    "            name = user_input.split(\"my name is\")[-1].strip().split()[0]\n",
    "            self.update_profile(\"name\", name)\n",
    "        \n",
    "        # Check for important facts\n",
    "        if \"remember this\" in user_input.lower() or \"important:\" in user_input.lower():\n",
    "            self.add_important_fact(user_input)\n",
    "        \n",
    "        # Build context from persistent memory\n",
    "        profile_str = json.dumps(self.memory[\"user_profile\"], indent=2)\n",
    "        recent_convos = self.memory[\"conversations\"][-5:] if self.memory[\"conversations\"] else []\n",
    "        important_facts = [f[\"fact\"] for f in self.memory[\"important_facts\"][-3:]]\n",
    "        \n",
    "        prompt = f\"\"\"You are a helpful assistant with persistent memory across sessions.\n",
    "        \n",
    "        User Profile:\n",
    "        {profile_str}\n",
    "        \n",
    "        Important Facts to Remember:\n",
    "        {json.dumps(important_facts, indent=2)}\n",
    "        \n",
    "        Session Number: {self.memory['session_count']}\n",
    "        \n",
    "        Current Conversation:\n",
    "        Human: {user_input}\n",
    "        \n",
    "        Assistant (reference their profile and history when relevant):\"\"\"\n",
    "        \n",
    "        response = self.llm.predict(prompt)\n",
    "        \n",
    "        # Save conversation\n",
    "        convo_entry = {\n",
    "            \"session\": self.memory[\"session_count\"],\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"human\": user_input,\n",
    "            \"ai\": response\n",
    "        }\n",
    "        self.memory[\"conversations\"].append(convo_entry)\n",
    "        \n",
    "        # Keep only last 100 conversations to manage file size\n",
    "        if len(self.memory[\"conversations\"]) > 100:\n",
    "            self.memory[\"conversations\"] = self.memory[\"conversations\"][-100:]\n",
    "        \n",
    "        self._save_memory()\n",
    "        return response\n",
    "    \n",
    "    def get_summary(self) -> str:\n",
    "        \"\"\"Get a summary of stored memory.\"\"\"\n",
    "        return f\"\"\"Memory Summary:\n",
    "        - Total sessions: {self.memory['session_count']}\n",
    "        - User profile entries: {len(self.memory['user_profile'])}\n",
    "        - Conversations stored: {len(self.memory['conversations'])}\n",
    "        - Important facts: {len(self.memory['important_facts'])}\n",
    "        \"\"\"\n",
    "\n",
    "# Test persistent memory\n",
    "persistent_chat = PersistentMemory(\"test_memory.json\")\n",
    "\n",
    "print(\"Persistent Memory Chat:\\n\")\n",
    "print(persistent_chat.start_session())\n",
    "print()\n",
    "\n",
    "# Simulate conversation\n",
    "persistent_messages = [\n",
    "    \"Hi! My name is Charlie and I'm a data scientist.\",\n",
    "    \"Remember this: My birthday is April 15th.\",\n",
    "    \"I'm working on a machine learning project about customer churn.\",\n",
    "    \"Important: I'm allergic to peanuts.\",\n",
    "    \"What do you remember about me?\"\n",
    "]\n",
    "\n",
    "for msg in persistent_messages:\n",
    "    print(f\"Human: {msg}\")\n",
    "    response = persistent_chat.chat(msg)\n",
    "    print(f\"AI: {response}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(persistent_chat.get_summary())\n",
    "\n",
    "# Clean up test file\n",
    "if os.path.exists(\"test_memory.json\"):\n",
    "    os.remove(\"test_memory.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "episodic_memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Episodic Memory - Remember specific events/episodes\n",
    "\n",
    "class EpisodicMemory:\n",
    "    \"\"\"Memory system that stores and retrieves specific episodes.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.episodes = []  # List of episode objects\n",
    "        self.llm = ChatOpenAI(temperature=0.7)\n",
    "        self.current_episode = None\n",
    "    \n",
    "    def start_episode(self, context: str):\n",
    "        \"\"\"Start a new episode.\"\"\"\n",
    "        self.current_episode = {\n",
    "            \"id\": len(self.episodes) + 1,\n",
    "            \"context\": context,\n",
    "            \"start_time\": datetime.now(),\n",
    "            \"events\": [],\n",
    "            \"summary\": None\n",
    "        }\n",
    "        return f\"Started episode: {context}\"\n",
    "    \n",
    "    def add_event(self, event: str, importance: int = 5):\n",
    "        \"\"\"Add an event to the current episode.\"\"\"\n",
    "        if self.current_episode:\n",
    "            self.current_episode[\"events\"].append({\n",
    "                \"event\": event,\n",
    "                \"timestamp\": datetime.now(),\n",
    "                \"importance\": importance\n",
    "            })\n",
    "    \n",
    "    def end_episode(self):\n",
    "        \"\"\"End current episode and generate summary.\"\"\"\n",
    "        if self.current_episode:\n",
    "            # Generate episode summary\n",
    "            events_str = \"\\n\".join([e[\"event\"] for e in self.current_episode[\"events\"]])\n",
    "            \n",
    "            summary_prompt = f\"\"\"Summarize this episode in 1-2 sentences:\n",
    "            Context: {self.current_episode['context']}\n",
    "            Events: {events_str}\n",
    "            \n",
    "            Summary:\"\"\"\n",
    "            \n",
    "            self.current_episode[\"summary\"] = self.llm.predict(summary_prompt)\n",
    "            self.current_episode[\"end_time\"] = datetime.now()\n",
    "            \n",
    "            self.episodes.append(self.current_episode)\n",
    "            summary = self.current_episode[\"summary\"]\n",
    "            self.current_episode = None\n",
    "            \n",
    "            return f\"Episode ended. Summary: {summary}\"\n",
    "        return \"No active episode\"\n",
    "    \n",
    "    def recall_similar_episodes(self, query: str, top_k: int = 3):\n",
    "        \"\"\"Find episodes similar to the query.\"\"\"\n",
    "        if not self.episodes:\n",
    "            return []\n",
    "        \n",
    "        # Simple similarity based on keyword matching\n",
    "        # In production, use embeddings\n",
    "        query_words = set(query.lower().split())\n",
    "        \n",
    "        scored_episodes = []\n",
    "        for episode in self.episodes:\n",
    "            # Score based on context and events\n",
    "            episode_text = episode[\"context\"] + \" \" + \" \".join([e[\"event\"] for e in episode[\"events\"]])\n",
    "            episode_words = set(episode_text.lower().split())\n",
    "            \n",
    "            # Jaccard similarity\n",
    "            intersection = query_words.intersection(episode_words)\n",
    "            union = query_words.union(episode_words)\n",
    "            score = len(intersection) / len(union) if union else 0\n",
    "            \n",
    "            scored_episodes.append((score, episode))\n",
    "        \n",
    "        # Sort by score and return top k\n",
    "        scored_episodes.sort(key=lambda x: x[0], reverse=True)\n",
    "        return [ep for _, ep in scored_episodes[:top_k]]\n",
    "    \n",
    "    def chat_with_episodic_recall(self, user_input: str) -> str:\n",
    "        \"\"\"Chat with episodic memory recall.\"\"\"\n",
    "        # Add to current episode if active\n",
    "        if self.current_episode:\n",
    "            self.add_event(f\"User said: {user_input}\")\n",
    "        \n",
    "        # Recall relevant episodes\n",
    "        relevant_episodes = self.recall_similar_episodes(user_input, top_k=2)\n",
    "        \n",
    "        # Format episodes for context\n",
    "        episodes_context = \"\"\n",
    "        if relevant_episodes:\n",
    "            episodes_context = \"Relevant past episodes:\\n\"\n",
    "            for ep in relevant_episodes:\n",
    "                episodes_context += f\"- {ep['context']}: {ep['summary']}\\n\"\n",
    "        \n",
    "        prompt = f\"\"\"You are an AI with episodic memory. You remember specific events and experiences.\n",
    "        \n",
    "        {episodes_context}\n",
    "        \n",
    "        Current episode: {self.current_episode['context'] if self.current_episode else 'No active episode'}\n",
    "        \n",
    "        Human: {user_input}\n",
    "        \n",
    "        Assistant (reference relevant episodes when appropriate):\"\"\"\n",
    "        \n",
    "        response = self.llm.predict(prompt)\n",
    "        \n",
    "        # Add response to episode\n",
    "        if self.current_episode:\n",
    "            self.add_event(f\"AI responded: {response[:100]}...\")\n",
    "        \n",
    "        return response\n",
    "\n",
    "# Test episodic memory\n",
    "episodic_memory = EpisodicMemory()\n",
    "\n",
    "print(\"Episodic Memory System:\\n\")\n",
    "\n",
    "# Episode 1: Learning Python\n",
    "print(episodic_memory.start_episode(\"Learning Python Session\"))\n",
    "print()\n",
    "\n",
    "episode1_interactions = [\n",
    "    \"I want to learn about Python functions.\",\n",
    "    \"Show me an example of a decorator.\",\n",
    "    \"How do I handle exceptions?\"\n",
    "]\n",
    "\n",
    "for msg in episode1_interactions:\n",
    "    print(f\"Human: {msg}\")\n",
    "    response = episodic_memory.chat_with_episodic_recall(msg)\n",
    "    print(f\"AI: {response[:150]}...\\n\")\n",
    "\n",
    "print(episodic_memory.end_episode())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Episode 2: Project Planning\n",
    "print(episodic_memory.start_episode(\"Project Planning Meeting\"))\n",
    "print()\n",
    "\n",
    "episode2_interactions = [\n",
    "    \"We need to build a web application.\",\n",
    "    \"It should have user authentication.\",\n",
    "    \"Let's use Python for the backend.\"\n",
    "]\n",
    "\n",
    "for msg in episode2_interactions:\n",
    "    print(f\"Human: {msg}\")\n",
    "    response = episodic_memory.chat_with_episodic_recall(msg)\n",
    "    print(f\"AI: {response[:150]}...\\n\")\n",
    "\n",
    "print(episodic_memory.end_episode())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Query about past episodes\n",
    "print(\"Querying past episodes:\\n\")\n",
    "query = \"What did we discuss about Python?\"\n",
    "print(f\"Human: {query}\")\n",
    "response = episodic_memory.chat_with_episodic_recall(query)\n",
    "print(f\"AI: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "learner_2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Learner Activity 2: Build a Learning Assistant with Adaptive Memory\n",
    "\n",
    "Create an assistant that adapts its memory strategy based on the conversation type.\n",
    "\n",
    "**Task**: Build an assistant that:\n",
    "1. Detects conversation type (casual chat, learning session, problem-solving)\n",
    "2. Uses appropriate memory strategy for each type\n",
    "3. Can switch between memory modes\n",
    "4. Tracks learning progress over time\n",
    "5. Provides summaries and reviews\n",
    "\n",
    "Requirements:\n",
    "- Implement at least 3 different memory strategies\n",
    "- Auto-detect conversation type\n",
    "- Track topic progression\n",
    "- Generate learning summaries\n",
    "- Handle context switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "learner_2_starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your adaptive learning assistant\n",
    "\n",
    "class AdaptiveLearningAssistant:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0.7)\n",
    "        # TODO: Initialize different memory systems\n",
    "        # - Casual chat memory (buffer window)\n",
    "        # - Learning memory (episodic + summary)\n",
    "        # - Problem-solving memory (entity + vector)\n",
    "        pass\n",
    "    \n",
    "    def detect_conversation_type(self, user_input: str) -> str:\n",
    "        \"\"\"Detect the type of conversation.\"\"\"\n",
    "        # TODO: Implement detection logic\n",
    "        # Return: \"casual\", \"learning\", or \"problem_solving\"\n",
    "        pass\n",
    "    \n",
    "    def switch_memory_mode(self, mode: str):\n",
    "        \"\"\"Switch to appropriate memory strategy.\"\"\"\n",
    "        # TODO: Implement mode switching\n",
    "        pass\n",
    "    \n",
    "    def track_learning_progress(self, topic: str, understanding_level: float):\n",
    "        \"\"\"Track user's learning progress.\"\"\"\n",
    "        # TODO: Implement progress tracking\n",
    "        pass\n",
    "    \n",
    "    def generate_learning_summary(self, topic: str) -> str:\n",
    "        \"\"\"Generate a summary of what was learned.\"\"\"\n",
    "        # TODO: Implement summary generation\n",
    "        pass\n",
    "    \n",
    "    def chat(self, user_input: str) -> str:\n",
    "        \"\"\"Adaptive chat interface.\"\"\"\n",
    "        # TODO: Implement adaptive chat\n",
    "        # - Detect conversation type\n",
    "        # - Use appropriate memory\n",
    "        # - Track progress if learning\n",
    "        # - Generate contextual response\n",
    "        pass\n",
    "\n",
    "# TODO: Test your adaptive assistant\n",
    "# Test with different conversation types\n",
    "# Verify memory adaptation\n",
    "\n",
    "# Your test code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "learner_2_solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution (hidden by default)\n",
    "\n",
    "\"\"\"\n",
    "class AdaptiveLearningAssistant:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0.7)\n",
    "        \n",
    "        # Different memory systems\n",
    "        # Casual chat - light memory\n",
    "        self.casual_memory = ConversationBufferWindowMemory(\n",
    "            memory_key=\"casual_chat\",\n",
    "            return_messages=True,\n",
    "            k=3\n",
    "        )\n",
    "        \n",
    "        # Learning - comprehensive memory\n",
    "        self.learning_memory = ConversationSummaryMemory(\n",
    "            llm=self.llm,\n",
    "            memory_key=\"learning_summary\",\n",
    "            return_messages=False\n",
    "        )\n",
    "        \n",
    "        # Problem-solving - detailed entity tracking\n",
    "        self.problem_memory = ConversationEntityMemory(\n",
    "            llm=self.llm,\n",
    "            memory_key=\"problem_entities\",\n",
    "            return_messages=False\n",
    "        )\n",
    "        \n",
    "        # Track learning progress\n",
    "        self.learning_progress = {}\n",
    "        self.conversation_history = []\n",
    "        self.current_mode = None\n",
    "        self.current_topic = None\n",
    "        \n",
    "        # Episode tracking for learning\n",
    "        self.learning_episodes = []\n",
    "        self.current_episode = None\n",
    "    \n",
    "    def detect_conversation_type(self, user_input: str) -> str:\n",
    "        '''Detect the type of conversation using keywords and patterns.'''\n",
    "        \n",
    "        # Learning indicators\n",
    "        learning_keywords = ['learn', 'teach', 'explain', 'understand', 'how does', \n",
    "                           'what is', 'why', 'tutorial', 'lesson', 'study']\n",
    "        \n",
    "        # Problem-solving indicators\n",
    "        problem_keywords = ['solve', 'fix', 'debug', 'issue', 'problem', 'error',\n",
    "                          'help me', 'stuck', 'wrong', 'broken', 'calculate']\n",
    "        \n",
    "        # Casual chat indicators\n",
    "        casual_keywords = ['hi', 'hello', 'how are', 'weather', 'joke', 'story',\n",
    "                         'opinion', 'think about', 'feeling']\n",
    "        \n",
    "        input_lower = user_input.lower()\n",
    "        \n",
    "        # Count keyword matches\n",
    "        learning_score = sum(1 for kw in learning_keywords if kw in input_lower)\n",
    "        problem_score = sum(1 for kw in problem_keywords if kw in input_lower)\n",
    "        casual_score = sum(1 for kw in casual_keywords if kw in input_lower)\n",
    "        \n",
    "        # Check for questions\n",
    "        if '?' in user_input:\n",
    "            learning_score += 1\n",
    "        \n",
    "        # Determine type based on scores\n",
    "        if learning_score > max(problem_score, casual_score):\n",
    "            return \"learning\"\n",
    "        elif problem_score > casual_score:\n",
    "            return \"problem_solving\"\n",
    "        else:\n",
    "            return \"casual\"\n",
    "    \n",
    "    def switch_memory_mode(self, mode: str):\n",
    "        '''Switch to appropriate memory strategy.'''\n",
    "        if mode != self.current_mode:\n",
    "            if self.current_mode == \"learning\" and self.current_episode:\n",
    "                # End learning episode\n",
    "                self._end_learning_episode()\n",
    "            \n",
    "            self.current_mode = mode\n",
    "            \n",
    "            if mode == \"learning\":\n",
    "                # Start new learning episode\n",
    "                self._start_learning_episode()\n",
    "    \n",
    "    def _start_learning_episode(self):\n",
    "        '''Start a new learning episode.'''\n",
    "        self.current_episode = {\n",
    "            \"start_time\": datetime.now(),\n",
    "            \"topics\": [],\n",
    "            \"concepts_learned\": [],\n",
    "            \"questions_asked\": [],\n",
    "            \"understanding_checkpoints\": []\n",
    "        }\n",
    "    \n",
    "    def _end_learning_episode(self):\n",
    "        '''End current learning episode.'''\n",
    "        if self.current_episode:\n",
    "            self.current_episode[\"end_time\"] = datetime.now()\n",
    "            self.current_episode[\"duration\"] = (\n",
    "                self.current_episode[\"end_time\"] - self.current_episode[\"start_time\"]\n",
    "            ).total_seconds() / 60  # in minutes\n",
    "            \n",
    "            # Generate episode summary\n",
    "            topics = \", \".join(self.current_episode[\"topics\"])\n",
    "            self.current_episode[\"summary\"] = f\"Learned about: {topics}\"\n",
    "            \n",
    "            self.learning_episodes.append(self.current_episode)\n",
    "            self.current_episode = None\n",
    "    \n",
    "    def track_learning_progress(self, topic: str, understanding_level: float):\n",
    "        '''Track user's learning progress on topics.'''\n",
    "        if topic not in self.learning_progress:\n",
    "            self.learning_progress[topic] = {\n",
    "                \"first_encountered\": datetime.now(),\n",
    "                \"understanding_history\": [],\n",
    "                \"total_interactions\": 0\n",
    "            }\n",
    "        \n",
    "        self.learning_progress[topic][\"understanding_history\"].append({\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"level\": understanding_level\n",
    "        })\n",
    "        self.learning_progress[topic][\"total_interactions\"] += 1\n",
    "        \n",
    "        # Update current episode\n",
    "        if self.current_episode and topic not in self.current_episode[\"topics\"]:\n",
    "            self.current_episode[\"topics\"].append(topic)\n",
    "    \n",
    "    def generate_learning_summary(self, topic: str = None) -> str:\n",
    "        '''Generate a summary of learning progress.'''\n",
    "        if topic and topic in self.learning_progress:\n",
    "            progress = self.learning_progress[topic]\n",
    "            latest_level = progress[\"understanding_history\"][-1][\"level\"] if progress[\"understanding_history\"] else 0\n",
    "            \n",
    "            return f'''Learning Summary for {topic}:\n",
    "            - First encountered: {progress[\"first_encountered\"].strftime(\"%Y-%m-%d\")}\n",
    "            - Total interactions: {progress[\"total_interactions\"]}\n",
    "            - Current understanding: {latest_level:.1%}\n",
    "            - Progress trend: {'Improving' if len(progress[\"understanding_history\"]) > 1 and \n",
    "                            progress[\"understanding_history\"][-1][\"level\"] > \n",
    "                            progress[\"understanding_history\"][0][\"level\"] else 'Stable'}'''\n",
    "        else:\n",
    "            # Overall summary\n",
    "            total_topics = len(self.learning_progress)\n",
    "            recent_topics = list(self.learning_progress.keys())[-3:] if self.learning_progress else []\n",
    "            \n",
    "            return f'''Overall Learning Summary:\n",
    "            - Topics studied: {total_topics}\n",
    "            - Recent topics: {', '.join(recent_topics)}\n",
    "            - Learning sessions: {len(self.learning_episodes)}'''\n",
    "    \n",
    "    def _extract_topic(self, user_input: str) -> str:\n",
    "        '''Extract the main topic from user input.'''\n",
    "        # Simple extraction - in production, use NLP\n",
    "        stop_words = ['the', 'a', 'an', 'is', 'are', 'what', 'how', 'why', 'can', 'you']\n",
    "        words = user_input.lower().split()\n",
    "        content_words = [w for w in words if w not in stop_words and len(w) > 3]\n",
    "        \n",
    "        if content_words:\n",
    "            return content_words[0]  # Simple: take first content word\n",
    "        return \"general\"\n",
    "    \n",
    "    def chat(self, user_input: str) -> str:\n",
    "        '''Adaptive chat interface.'''\n",
    "        \n",
    "        # Detect conversation type\n",
    "        conv_type = self.detect_conversation_type(user_input)\n",
    "        self.switch_memory_mode(conv_type)\n",
    "        \n",
    "        # Extract topic for learning mode\n",
    "        if conv_type == \"learning\":\n",
    "            topic = self._extract_topic(user_input)\n",
    "            self.current_topic = topic\n",
    "            \n",
    "            # Add to current episode\n",
    "            if self.current_episode:\n",
    "                self.current_episode[\"questions_asked\"].append(user_input)\n",
    "        \n",
    "        # Build prompt based on mode\n",
    "        if conv_type == \"casual\":\n",
    "            memory_context = self.casual_memory.load_memory_variables({})\n",
    "            prompt = f'''You are a friendly assistant having a casual conversation.\n",
    "            \n",
    "            Recent chat:\n",
    "            {memory_context.get(\"casual_chat\", \"\")}\n",
    "            \n",
    "            Human: {user_input}\n",
    "            Assistant (be friendly and conversational):'''\n",
    "            \n",
    "        elif conv_type == \"learning\":\n",
    "            memory_context = self.learning_memory.load_memory_variables({})\n",
    "            progress_summary = self.generate_learning_summary(self.current_topic)\n",
    "            \n",
    "            prompt = f'''You are a patient teacher helping someone learn.\n",
    "            \n",
    "            Learning context:\n",
    "            {memory_context.get(\"learning_summary\", \"\")}\n",
    "            \n",
    "            Progress:\n",
    "            {progress_summary}\n",
    "            \n",
    "            Human: {user_input}\n",
    "            Teacher (explain clearly, use examples, check understanding):'''\n",
    "            \n",
    "        else:  # problem_solving\n",
    "            memory_context = self.problem_memory.load_memory_variables({\"input\": user_input})\n",
    "            \n",
    "            prompt = f'''You are a problem-solving assistant.\n",
    "            \n",
    "            Problem context and entities:\n",
    "            {memory_context.get(\"problem_entities\", \"\")}\n",
    "            \n",
    "            Human: {user_input}\n",
    "            Assistant (be systematic, break down the problem, provide solutions):'''\n",
    "        \n",
    "        # Get response\n",
    "        response = self.llm.predict(prompt)\n",
    "        \n",
    "        # Save to appropriate memory\n",
    "        context = {\"input\": user_input}\n",
    "        output = {\"output\": response}\n",
    "        \n",
    "        if conv_type == \"casual\":\n",
    "            self.casual_memory.save_context(context, output)\n",
    "        elif conv_type == \"learning\":\n",
    "            self.learning_memory.save_context(context, output)\n",
    "            # Track progress (simple heuristic)\n",
    "            understanding = 0.7 if \"understand\" in response.lower() else 0.5\n",
    "            self.track_learning_progress(self.current_topic, understanding)\n",
    "        else:\n",
    "            self.problem_memory.save_context(context, output)\n",
    "        \n",
    "        # Add mode indicator to response\n",
    "        mode_indicator = f\"[Mode: {conv_type}] \"\n",
    "        \n",
    "        return mode_indicator + response\n",
    "\n",
    "# Test the adaptive assistant\n",
    "print(\"Adaptive Learning Assistant Demo\\n\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "assistant = AdaptiveLearningAssistant()\n",
    "\n",
    "# Test different conversation types\n",
    "test_conversations = [\n",
    "    # Casual\n",
    "    \"Hi! How are you today?\",\n",
    "    # Learning\n",
    "    \"Can you explain what recursion is in programming?\",\n",
    "    \"Show me an example of recursion.\",\n",
    "    # Problem-solving\n",
    "    \"I'm getting a TypeError in my Python code when I try to add a string and number.\",\n",
    "    # Back to learning\n",
    "    \"What are the main principles of object-oriented programming?\",\n",
    "    # Summary request\n",
    "    \"What have I learned so far?\",\n",
    "    # Casual again\n",
    "    \"Thanks for the help! You're really good at explaining things.\"\n",
    "]\n",
    "\n",
    "for msg in test_conversations:\n",
    "    print(f\"\\nHuman: {msg}\")\n",
    "    response = assistant.chat(msg)\n",
    "    # Show first part of response\n",
    "    if len(response) > 200:\n",
    "        print(f\"AI: {response[:200]}...\")\n",
    "    else:\n",
    "        print(f\"AI: {response}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nLearning Progress Summary:\")\n",
    "print(assistant.generate_learning_summary())\n",
    "\n",
    "if assistant.learning_progress:\n",
    "    print(\"\\nTopics covered:\")\n",
    "    for topic in assistant.learning_progress:\n",
    "        print(f\"- {topic}\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Build an adaptive learning assistant with multiple memory strategies!\")\n",
    "print(\"The solution shows conversation type detection and appropriate memory usage.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructor_3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Instructor Activity 3: Production Memory Systems\n",
    "\n",
    "Let's build production-ready memory systems with databases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "production_memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production Memory with SQLite\n",
    "\n",
    "import sqlite3\n",
    "from typing import List, Dict, Optional\n",
    "import json\n",
    "\n",
    "class SQLiteMemory:\n",
    "    \"\"\"Production-ready memory system using SQLite.\"\"\"\n",
    "    \n",
    "    def __init__(self, db_path: str = \"conversation_memory.db\"):\n",
    "        self.db_path = db_path\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self._init_database()\n",
    "        self.llm = ChatOpenAI(temperature=0.7)\n",
    "    \n",
    "    def _init_database(self):\n",
    "        \"\"\"Initialize database tables.\"\"\"\n",
    "        cursor = self.conn.cursor()\n",
    "        \n",
    "        # Conversations table\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS conversations (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                session_id TEXT NOT NULL,\n",
    "                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "                role TEXT NOT NULL,\n",
    "                content TEXT NOT NULL,\n",
    "                metadata TEXT\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        # User profiles table\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS user_profiles (\n",
    "                user_id TEXT PRIMARY KEY,\n",
    "                profile_data TEXT NOT NULL,\n",
    "                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        # Topics table\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS topics (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                session_id TEXT NOT NULL,\n",
    "                topic TEXT NOT NULL,\n",
    "                importance REAL DEFAULT 0.5,\n",
    "                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        # Create indexes for performance\n",
    "        cursor.execute('CREATE INDEX IF NOT EXISTS idx_session ON conversations(session_id)')\n",
    "        cursor.execute('CREATE INDEX IF NOT EXISTS idx_timestamp ON conversations(timestamp)')\n",
    "        \n",
    "        self.conn.commit()\n",
    "    \n",
    "    def save_message(self, session_id: str, role: str, content: str, metadata: Dict = None):\n",
    "        \"\"\"Save a message to the database.\"\"\"\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute(\n",
    "            'INSERT INTO conversations (session_id, role, content, metadata) VALUES (?, ?, ?, ?)',\n",
    "            (session_id, role, content, json.dumps(metadata) if metadata else None)\n",
    "        )\n",
    "        self.conn.commit()\n",
    "        return cursor.lastrowid\n",
    "    \n",
    "    def get_conversation_history(self, session_id: str, limit: int = 10) -> List[Dict]:\n",
    "        \"\"\"Retrieve conversation history for a session.\"\"\"\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute(\n",
    "            '''SELECT role, content, timestamp, metadata \n",
    "               FROM conversations \n",
    "               WHERE session_id = ? \n",
    "               ORDER BY timestamp DESC \n",
    "               LIMIT ?''',\n",
    "            (session_id, limit)\n",
    "        )\n",
    "        \n",
    "        rows = cursor.fetchall()\n",
    "        return [\n",
    "            {\n",
    "                \"role\": row[0],\n",
    "                \"content\": row[1],\n",
    "                \"timestamp\": row[2],\n",
    "                \"metadata\": json.loads(row[3]) if row[3] else None\n",
    "            }\n",
    "            for row in reversed(rows)  # Reverse to get chronological order\n",
    "        ]\n",
    "    \n",
    "    def search_conversations(self, query: str, limit: int = 5) -> List[Dict]:\n",
    "        \"\"\"Search conversations using full-text search.\"\"\"\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute(\n",
    "            '''SELECT session_id, role, content, timestamp \n",
    "               FROM conversations \n",
    "               WHERE content LIKE ? \n",
    "               ORDER BY timestamp DESC \n",
    "               LIMIT ?''',\n",
    "            (f'%{query}%', limit)\n",
    "        )\n",
    "        \n",
    "        rows = cursor.fetchall()\n",
    "        return [\n",
    "            {\n",
    "                \"session_id\": row[0],\n",
    "                \"role\": row[1],\n",
    "                \"content\": row[2],\n",
    "                \"timestamp\": row[3]\n",
    "            }\n",
    "            for row in rows\n",
    "        ]\n",
    "    \n",
    "    def update_user_profile(self, user_id: str, profile_data: Dict):\n",
    "        \"\"\"Update or create user profile.\"\"\"\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute(\n",
    "            '''INSERT INTO user_profiles (user_id, profile_data) \n",
    "               VALUES (?, ?) \n",
    "               ON CONFLICT(user_id) \n",
    "               DO UPDATE SET profile_data = ?, updated_at = CURRENT_TIMESTAMP''',\n",
    "            (user_id, json.dumps(profile_data), json.dumps(profile_data))\n",
    "        )\n",
    "        self.conn.commit()\n",
    "    \n",
    "    def get_user_profile(self, user_id: str) -> Optional[Dict]:\n",
    "        \"\"\"Retrieve user profile.\"\"\"\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute(\n",
    "            'SELECT profile_data FROM user_profiles WHERE user_id = ?',\n",
    "            (user_id,)\n",
    "        )\n",
    "        row = cursor.fetchone()\n",
    "        return json.loads(row[0]) if row else None\n",
    "    \n",
    "    def save_topic(self, session_id: str, topic: str, importance: float = 0.5):\n",
    "        \"\"\"Save a topic discussed in the conversation.\"\"\"\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute(\n",
    "            'INSERT INTO topics (session_id, topic, importance) VALUES (?, ?, ?)',\n",
    "            (session_id, topic, importance)\n",
    "        )\n",
    "        self.conn.commit()\n",
    "    \n",
    "    def get_session_summary(self, session_id: str) -> str:\n",
    "        \"\"\"Generate a summary of a session.\"\"\"\n",
    "        history = self.get_conversation_history(session_id, limit=50)\n",
    "        \n",
    "        if not history:\n",
    "            return \"No conversation history found.\"\n",
    "        \n",
    "        # Format conversation for summarization\n",
    "        conversation = \"\\n\".join([\n",
    "            f\"{msg['role']}: {msg['content']}\" \n",
    "            for msg in history\n",
    "        ])\n",
    "        \n",
    "        # Generate summary\n",
    "        summary_prompt = f\"\"\"Summarize this conversation in 2-3 sentences:\n",
    "        {conversation}\n",
    "        \n",
    "        Summary:\"\"\"\n",
    "        \n",
    "        summary = self.llm.predict(summary_prompt)\n",
    "        return summary\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close database connection.\"\"\"\n",
    "        self.conn.close()\n",
    "\n",
    "# Test SQLite memory\n",
    "print(\"SQLite Memory System Demo:\\n\")\n",
    "\n",
    "# Create memory system\n",
    "db_memory = SQLiteMemory(\"test_memory.db\")\n",
    "\n",
    "# Simulate conversation\n",
    "session_id = \"session_001\"\n",
    "user_id = \"user_123\"\n",
    "\n",
    "# Save user profile\n",
    "profile = {\n",
    "    \"name\": \"David\",\n",
    "    \"interests\": [\"AI\", \"robotics\", \"space\"],\n",
    "    \"learning_style\": \"visual\"\n",
    "}\n",
    "db_memory.update_user_profile(user_id, profile)\n",
    "\n",
    "# Simulate conversation\n",
    "messages = [\n",
    "    (\"user\", \"Hi! I want to learn about neural networks.\"),\n",
    "    (\"assistant\", \"Great! Neural networks are computational models inspired by the human brain.\"),\n",
    "    (\"user\", \"How do they learn?\"),\n",
    "    (\"assistant\", \"They learn through backpropagation, adjusting weights based on errors.\")\n",
    "]\n",
    "\n",
    "for role, content in messages:\n",
    "    db_memory.save_message(session_id, role, content)\n",
    "    print(f\"{role.capitalize()}: {content}\")\n",
    "\n",
    "# Save topic\n",
    "db_memory.save_topic(session_id, \"neural networks\", importance=0.9)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nRetrieved User Profile:\")\n",
    "retrieved_profile = db_memory.get_user_profile(user_id)\n",
    "print(json.dumps(retrieved_profile, indent=2))\n",
    "\n",
    "print(\"\\nConversation History:\")\n",
    "history = db_memory.get_conversation_history(session_id)\n",
    "for msg in history:\n",
    "    print(f\"{msg['role']}: {msg['content'][:50]}...\")\n",
    "\n",
    "print(\"\\nSession Summary:\")\n",
    "summary = db_memory.get_session_summary(session_id)\n",
    "print(summary)\n",
    "\n",
    "# Clean up\n",
    "db_memory.close()\n",
    "import os\n",
    "if os.path.exists(\"test_memory.db\"):\n",
    "    os.remove(\"test_memory.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "learner_3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Learner Activity 3: Build a Complete Memory Management System\n",
    "\n",
    "Create a comprehensive memory system for a production chatbot.\n",
    "\n",
    "**Task**: Build a memory system that:\n",
    "1. Supports multiple users with separate memory spaces\n",
    "2. Implements memory compression for long conversations  \n",
    "3. Provides memory search and retrieval\n",
    "4. Includes memory persistence and backup\n",
    "5. Handles memory privacy and data retention policies\n",
    "6. Supports memory export and import\n",
    "\n",
    "Requirements:\n",
    "- Multi-user support with isolation\n",
    "- Automatic memory compression\n",
    "- Full-text search capability\n",
    "- Data retention policies\n",
    "- Export/import functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "learner_3_starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your complete memory management system\n",
    "\n",
    "class MemoryManagementSystem:\n",
    "    def __init__(self, storage_path: str = \"memory_store\"):\n",
    "        self.storage_path = storage_path\n",
    "        # TODO: Initialize storage backend\n",
    "        # TODO: Set up user management\n",
    "        # TODO: Configure retention policies\n",
    "        pass\n",
    "    \n",
    "    def create_user_space(self, user_id: str) -> bool:\n",
    "        \"\"\"Create isolated memory space for user.\"\"\"\n",
    "        # TODO: Implement user space creation\n",
    "        pass\n",
    "    \n",
    "    def compress_memory(self, user_id: str, strategy: str = \"summary\"):\n",
    "        \"\"\"Compress old memories to save space.\"\"\"\n",
    "        # TODO: Implement memory compression\n",
    "        # Strategies: summary, selective, hierarchical\n",
    "        pass\n",
    "    \n",
    "    def search_memory(self, user_id: str, query: str, filters: Dict = None) -> List[Dict]:\n",
    "        \"\"\"Search user's memory with filters.\"\"\"\n",
    "        # TODO: Implement semantic and keyword search\n",
    "        pass\n",
    "    \n",
    "    def apply_retention_policy(self, user_id: str, policy: Dict):\n",
    "        \"\"\"Apply data retention policy.\"\"\"\n",
    "        # TODO: Implement retention policies\n",
    "        # e.g., delete after 30 days, anonymize after 90 days\n",
    "        pass\n",
    "    \n",
    "    def export_memory(self, user_id: str, format: str = \"json\") -> str:\n",
    "        \"\"\"Export user's memory.\"\"\"\n",
    "        # TODO: Implement export in different formats\n",
    "        pass\n",
    "    \n",
    "    def import_memory(self, user_id: str, data: str, format: str = \"json\") -> bool:\n",
    "        \"\"\"Import memory data.\"\"\"\n",
    "        # TODO: Implement import with validation\n",
    "        pass\n",
    "    \n",
    "    def get_memory_stats(self, user_id: str) -> Dict:\n",
    "        \"\"\"Get memory usage statistics.\"\"\"\n",
    "        # TODO: Implement statistics gathering\n",
    "        pass\n",
    "\n",
    "# TODO: Create comprehensive tests\n",
    "# Test multi-user scenarios\n",
    "# Test compression strategies\n",
    "# Test search functionality\n",
    "# Test export/import\n",
    "\n",
    "# Your test code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "learner_3_solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution (hidden by default)\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "import shutil\n",
    "import hashlib\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "class MemoryManagementSystem:\n",
    "    def __init__(self, storage_path: str = \"memory_store\"):\n",
    "        self.storage_path = storage_path\n",
    "        self.llm = ChatOpenAI(temperature=0.7)\n",
    "        \n",
    "        # Create storage directory\n",
    "        os.makedirs(storage_path, exist_ok=True)\n",
    "        \n",
    "        # User management\n",
    "        self.users = {}\n",
    "        self.active_sessions = {}\n",
    "        \n",
    "        # Retention policies\n",
    "        self.default_retention = {\n",
    "            \"max_age_days\": 90,\n",
    "            \"max_messages\": 10000,\n",
    "            \"compression_threshold\": 1000,\n",
    "            \"anonymize_after_days\": 30\n",
    "        }\n",
    "        \n",
    "        # Initialize main database\n",
    "        self.db_path = os.path.join(storage_path, \"main.db\")\n",
    "        self._init_database()\n",
    "    \n",
    "    def _init_database(self):\n",
    "        '''Initialize central database.'''\n",
    "        import sqlite3\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Users table\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS users (\n",
    "                user_id TEXT PRIMARY KEY,\n",
    "                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "                last_active DATETIME,\n",
    "                memory_size INTEGER DEFAULT 0,\n",
    "                message_count INTEGER DEFAULT 0,\n",
    "                settings TEXT\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        # Memory entries (centralized for search)\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS memories (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                user_id TEXT NOT NULL,\n",
    "                session_id TEXT,\n",
    "                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "                type TEXT,  -- 'message', 'summary', 'fact', etc.\n",
    "                content TEXT,\n",
    "                metadata TEXT,\n",
    "                compressed BOOLEAN DEFAULT 0,\n",
    "                FOREIGN KEY (user_id) REFERENCES users(user_id)\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        # Create indexes\n",
    "        cursor.execute('CREATE INDEX IF NOT EXISTS idx_user_memories ON memories(user_id)')\n",
    "        cursor.execute('CREATE INDEX IF NOT EXISTS idx_timestamp ON memories(timestamp)')\n",
    "        cursor.execute('CREATE INDEX IF NOT EXISTS idx_content ON memories(content)')  # For FTS\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    \n",
    "    def create_user_space(self, user_id: str) -> bool:\n",
    "        '''Create isolated memory space for user.'''\n",
    "        # Hash user_id for privacy\n",
    "        user_hash = hashlib.sha256(user_id.encode()).hexdigest()[:16]\n",
    "        user_path = os.path.join(self.storage_path, user_hash)\n",
    "        \n",
    "        if not os.path.exists(user_path):\n",
    "            os.makedirs(user_path)\n",
    "            \n",
    "            # Create user-specific database\n",
    "            user_db = os.path.join(user_path, \"memory.db\")\n",
    "            conn = sqlite3.connect(user_db)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # User's conversation memory\n",
    "            cursor.execute('''\n",
    "                CREATE TABLE conversations (\n",
    "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    session_id TEXT,\n",
    "                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "                    role TEXT,\n",
    "                    content TEXT,\n",
    "                    tokens INTEGER\n",
    "                )\n",
    "            ''')\n",
    "            \n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "            \n",
    "            # Register user in main database\n",
    "            conn = sqlite3.connect(self.db_path)\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\n",
    "                'INSERT OR IGNORE INTO users (user_id, last_active) VALUES (?, ?)',\n",
    "                (user_hash, datetime.now())\n",
    "            )\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "            \n",
    "            self.users[user_id] = {\n",
    "                \"hash\": user_hash,\n",
    "                \"path\": user_path,\n",
    "                \"created\": datetime.now()\n",
    "            }\n",
    "            \n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def compress_memory(self, user_id: str, strategy: str = \"summary\"):\n",
    "        '''Compress old memories to save space.'''\n",
    "        user_hash = hashlib.sha256(user_id.encode()).hexdigest()[:16]\n",
    "        \n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Get uncompressed memories older than 7 days\n",
    "        cutoff_date = datetime.now() - timedelta(days=7)\n",
    "        cursor.execute(\n",
    "            '''SELECT id, content, metadata FROM memories \n",
    "               WHERE user_id = ? AND compressed = 0 AND timestamp < ?\n",
    "               ORDER BY timestamp\n",
    "               LIMIT 100''',\n",
    "            (user_hash, cutoff_date)\n",
    "        )\n",
    "        \n",
    "        memories_to_compress = cursor.fetchall()\n",
    "        \n",
    "        if not memories_to_compress:\n",
    "            return \"No memories to compress.\"\n",
    "        \n",
    "        if strategy == \"summary\":\n",
    "            # Combine and summarize\n",
    "            combined = \"\\n\".join([m[1] for m in memories_to_compress[:20]])  # Take first 20\n",
    "            \n",
    "            summary_prompt = f'''Summarize these conversation memories concisely:\n",
    "            {combined[:2000]}  # Limit input length\n",
    "            \n",
    "            Summary:'''\n",
    "            \n",
    "            summary = self.llm.predict(summary_prompt)\n",
    "            \n",
    "            # Save compressed summary\n",
    "            cursor.execute(\n",
    "                '''INSERT INTO memories (user_id, type, content, compressed) \n",
    "                   VALUES (?, 'compressed_summary', ?, 1)''',\n",
    "                (user_hash, summary)\n",
    "            )\n",
    "            \n",
    "            # Mark originals as compressed\n",
    "            memory_ids = [m[0] for m in memories_to_compress[:20]]\n",
    "            cursor.execute(\n",
    "                f'UPDATE memories SET compressed = 1 WHERE id IN ({(\",\".join([\"?\"]*len(memory_ids)))})',\n",
    "                memory_ids\n",
    "            )\n",
    "            \n",
    "        elif strategy == \"selective\":\n",
    "            # Keep only important messages\n",
    "            important_keywords = ['important', 'remember', 'key', 'critical', 'must']\n",
    "            \n",
    "            for mem_id, content, metadata in memories_to_compress:\n",
    "                # Check importance\n",
    "                is_important = any(kw in content.lower() for kw in important_keywords)\n",
    "                \n",
    "                if not is_important:\n",
    "                    # Mark as compressed (effectively hiding it)\n",
    "                    cursor.execute(\n",
    "                        'UPDATE memories SET compressed = 1 WHERE id = ?',\n",
    "                        (mem_id,)\n",
    "                    )\n",
    "        \n",
    "        elif strategy == \"hierarchical\":\n",
    "            # Create hierarchical summaries\n",
    "            # Daily -> Weekly -> Monthly\n",
    "            pass  # Implementation left as exercise\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        \n",
    "        return f\"Compressed {len(memories_to_compress)} memories using {strategy} strategy.\"\n",
    "    \n",
    "    def search_memory(self, user_id: str, query: str, filters: Dict = None) -> List[Dict]:\n",
    "        '''Search user's memory with filters.'''\n",
    "        user_hash = hashlib.sha256(user_id.encode()).hexdigest()[:16]\n",
    "        \n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Build query\n",
    "        sql = '''SELECT id, timestamp, type, content, metadata \n",
    "                 FROM memories \n",
    "                 WHERE user_id = ? AND compressed = 0'''\n",
    "        \n",
    "        params = [user_hash]\n",
    "        \n",
    "        # Add search condition\n",
    "        if query:\n",
    "            sql += ' AND content LIKE ?'\n",
    "            params.append(f'%{query}%')\n",
    "        \n",
    "        # Add filters\n",
    "        if filters:\n",
    "            if 'type' in filters:\n",
    "                sql += ' AND type = ?'\n",
    "                params.append(filters['type'])\n",
    "            \n",
    "            if 'after' in filters:\n",
    "                sql += ' AND timestamp > ?'\n",
    "                params.append(filters['after'])\n",
    "        \n",
    "        sql += ' ORDER BY timestamp DESC LIMIT 20'\n",
    "        \n",
    "        cursor.execute(sql, params)\n",
    "        results = cursor.fetchall()\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "        return [\n",
    "            {\n",
    "                \"id\": r[0],\n",
    "                \"timestamp\": r[1],\n",
    "                \"type\": r[2],\n",
    "                \"content\": r[3],\n",
    "                \"metadata\": json.loads(r[4]) if r[4] else None\n",
    "            }\n",
    "            for r in results\n",
    "        ]\n",
    "    \n",
    "    def apply_retention_policy(self, user_id: str, policy: Dict = None):\n",
    "        '''Apply data retention policy.'''\n",
    "        user_hash = hashlib.sha256(user_id.encode()).hexdigest()[:16]\n",
    "        policy = policy or self.default_retention\n",
    "        \n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Delete old memories\n",
    "        if 'max_age_days' in policy:\n",
    "            cutoff = datetime.now() - timedelta(days=policy['max_age_days'])\n",
    "            cursor.execute(\n",
    "                'DELETE FROM memories WHERE user_id = ? AND timestamp < ?',\n",
    "                (user_hash, cutoff)\n",
    "            )\n",
    "        \n",
    "        # Limit total messages\n",
    "        if 'max_messages' in policy:\n",
    "            cursor.execute(\n",
    "                '''DELETE FROM memories \n",
    "                   WHERE user_id = ? AND id NOT IN (\n",
    "                       SELECT id FROM memories \n",
    "                       WHERE user_id = ? \n",
    "                       ORDER BY timestamp DESC \n",
    "                       LIMIT ?\n",
    "                   )''',\n",
    "                (user_hash, user_hash, policy['max_messages'])\n",
    "            )\n",
    "        \n",
    "        # Anonymize old data\n",
    "        if 'anonymize_after_days' in policy:\n",
    "            cutoff = datetime.now() - timedelta(days=policy['anonymize_after_days'])\n",
    "            # Simple anonymization - remove personal info\n",
    "            cursor.execute(\n",
    "                '''UPDATE memories \n",
    "                   SET content = '[ANONYMIZED]' || substr(content, -50)\n",
    "                   WHERE user_id = ? AND timestamp < ? AND content NOT LIKE '[ANONYMIZED]%' ''',\n",
    "                (user_hash, cutoff)\n",
    "            )\n",
    "        \n",
    "        conn.commit()\n",
    "        changes = conn.total_changes\n",
    "        conn.close()\n",
    "        \n",
    "        return f\"Retention policy applied. {changes} records affected.\"\n",
    "    \n",
    "    def export_memory(self, user_id: str, format: str = \"json\") -> str:\n",
    "        '''Export user's memory.'''\n",
    "        memories = self.search_memory(user_id, \"\", filters=None)\n",
    "        \n",
    "        if format == \"json\":\n",
    "            return json.dumps(memories, indent=2, default=str)\n",
    "        \n",
    "        elif format == \"csv\":\n",
    "            import csv\n",
    "            import io\n",
    "            \n",
    "            output = io.StringIO()\n",
    "            writer = csv.DictWriter(output, fieldnames=['timestamp', 'type', 'content'])\n",
    "            writer.writeheader()\n",
    "            \n",
    "            for mem in memories:\n",
    "                writer.writerow({\n",
    "                    'timestamp': mem['timestamp'],\n",
    "                    'type': mem['type'],\n",
    "                    'content': mem['content']\n",
    "                })\n",
    "            \n",
    "            return output.getvalue()\n",
    "        \n",
    "        elif format == \"markdown\":\n",
    "            output = \"# Memory Export\\n\\n\"\n",
    "            for mem in memories:\n",
    "                output += f\"## {mem['timestamp']}\\n\"\n",
    "                output += f\"Type: {mem['type']}\\n\\n\"\n",
    "                output += f\"{mem['content']}\\n\\n\"\n",
    "                output += \"---\\n\\n\"\n",
    "            return output\n",
    "        \n",
    "        return \"Unsupported format\"\n",
    "    \n",
    "    def import_memory(self, user_id: str, data: str, format: str = \"json\") -> bool:\n",
    "        '''Import memory data.'''\n",
    "        user_hash = hashlib.sha256(user_id.encode()).hexdigest()[:16]\n",
    "        \n",
    "        try:\n",
    "            if format == \"json\":\n",
    "                memories = json.loads(data)\n",
    "                \n",
    "                conn = sqlite3.connect(self.db_path)\n",
    "                cursor = conn.cursor()\n",
    "                \n",
    "                for mem in memories:\n",
    "                    cursor.execute(\n",
    "                        '''INSERT INTO memories (user_id, timestamp, type, content, metadata)\n",
    "                           VALUES (?, ?, ?, ?, ?)''',\n",
    "                        (\n",
    "                            user_hash,\n",
    "                            mem.get('timestamp', datetime.now()),\n",
    "                            mem.get('type', 'imported'),\n",
    "                            mem.get('content', ''),\n",
    "                            json.dumps(mem.get('metadata', {}))\n",
    "                        )\n",
    "                    )\n",
    "                \n",
    "                conn.commit()\n",
    "                conn.close()\n",
    "                return True\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Import error: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_memory_stats(self, user_id: str) -> Dict:\n",
    "        '''Get memory usage statistics.'''\n",
    "        user_hash = hashlib.sha256(user_id.encode()).hexdigest()[:16]\n",
    "        \n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Get counts\n",
    "        cursor.execute(\n",
    "            'SELECT COUNT(*), MIN(timestamp), MAX(timestamp) FROM memories WHERE user_id = ?',\n",
    "            (user_hash,)\n",
    "        )\n",
    "        count, oldest, newest = cursor.fetchone()\n",
    "        \n",
    "        # Get type distribution\n",
    "        cursor.execute(\n",
    "            'SELECT type, COUNT(*) FROM memories WHERE user_id = ? GROUP BY type',\n",
    "            (user_hash,)\n",
    "        )\n",
    "        type_dist = dict(cursor.fetchall())\n",
    "        \n",
    "        # Get compression stats\n",
    "        cursor.execute(\n",
    "            'SELECT compressed, COUNT(*) FROM memories WHERE user_id = ? GROUP BY compressed',\n",
    "            (user_hash,)\n",
    "        )\n",
    "        compression_stats = dict(cursor.fetchall())\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "        return {\n",
    "            \"total_memories\": count,\n",
    "            \"oldest_memory\": oldest,\n",
    "            \"newest_memory\": newest,\n",
    "            \"memory_types\": type_dist,\n",
    "            \"compressed\": compression_stats.get(1, 0),\n",
    "            \"uncompressed\": compression_stats.get(0, 0)\n",
    "        }\n",
    "\n",
    "# Test the system\n",
    "print(\"Complete Memory Management System Demo\\n\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create system\n",
    "mms = MemoryManagementSystem(\"test_memory_store\")\n",
    "\n",
    "# Create users\n",
    "users = [\"alice_123\", \"bob_456\"]\n",
    "for user in users:\n",
    "    mms.create_user_space(user)\n",
    "    print(f\"Created memory space for {user}\")\n",
    "\n",
    "# Add some memories\n",
    "import sqlite3\n",
    "user_hash = hashlib.sha256(\"alice_123\".encode()).hexdigest()[:16]\n",
    "\n",
    "conn = sqlite3.connect(mms.db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "test_memories = [\n",
    "    (\"message\", \"Hello, I'm learning about AI.\"),\n",
    "    (\"message\", \"Can you teach me about neural networks?\"),\n",
    "    (\"fact\", \"Important: My project deadline is next Friday.\"),\n",
    "    (\"message\", \"I understand backpropagation now!\"),\n",
    "]\n",
    "\n",
    "for mem_type, content in test_memories:\n",
    "    cursor.execute(\n",
    "        'INSERT INTO memories (user_id, type, content) VALUES (?, ?, ?)',\n",
    "        (user_hash, mem_type, content)\n",
    "    )\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"\\nAdded test memories\")\n",
    "\n",
    "# Test search\n",
    "print(\"\\nSearching for 'neural':\")\n",
    "results = mms.search_memory(\"alice_123\", \"neural\")\n",
    "for r in results:\n",
    "    print(f\"- {r['content'][:50]}...\")\n",
    "\n",
    "# Test compression\n",
    "print(\"\\nTesting compression:\")\n",
    "result = mms.compress_memory(\"alice_123\", \"summary\")\n",
    "print(result)\n",
    "\n",
    "# Test stats\n",
    "print(\"\\nMemory Statistics:\")\n",
    "stats = mms.get_memory_stats(\"alice_123\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"- {key}: {value}\")\n",
    "\n",
    "# Test export\n",
    "print(\"\\nExporting memory:\")\n",
    "exported = mms.export_memory(\"alice_123\", \"json\")\n",
    "print(f\"Exported {len(exported)} characters of data\")\n",
    "\n",
    "# Clean up\n",
    "import shutil\n",
    "if os.path.exists(\"test_memory_store\"):\n",
    "    shutil.rmtree(\"test_memory_store\")\n",
    "print(\"\\nCleanup complete!\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Build a complete production-ready memory management system!\")\n",
    "print(\"The solution includes multi-user support, compression, search, and retention policies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Next Steps\n",
    "\n",
    "Congratulations! You've mastered memory and conversation management in LangChain. You can now:\n",
    "\n",
    "✅ Implement different types of conversation memory\n",
    "✅ Build chatbots with context awareness\n",
    "✅ Use entity and summary memory effectively\n",
    "✅ Create episodic and semantic memory systems\n",
    "✅ Build production-ready persistent memory\n",
    "✅ Manage multi-user memory spaces\n",
    "\n",
    "### Key Takeaways:\n",
    "- **Memory Types Matter**: Choose the right memory for your use case\n",
    "- **Compression is Essential**: Long conversations need smart compression\n",
    "- **Persistence is Required**: Production systems need database backing\n",
    "- **Privacy Matters**: Implement proper data retention and anonymization\n",
    "- **Search Enables Intelligence**: Semantic search over memory improves responses\n",
    "\n",
    "### Next Steps:\n",
    "- **Notebook 10**: Learn about Streaming and Real-time interactions\n",
    "- **Practice**: Build conversational applications with memory\n",
    "- **Experiment**: Try different memory combinations\n",
    "- **Scale**: Implement distributed memory systems\n",
    "\n",
    "### Additional Challenges:\n",
    "1. Implement graph-based memory for relationship tracking\n",
    "2. Build a memory system with emotion tracking\n",
    "3. Create cross-session learning that improves over time\n",
    "4. Implement memory sharing between multiple agents\n",
    "5. Build a privacy-preserving federated memory system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}