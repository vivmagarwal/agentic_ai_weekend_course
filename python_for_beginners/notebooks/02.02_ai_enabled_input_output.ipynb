{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# **AI-Enabled Input/Output: Your First LLM Application**\n\n## **Learning Objectives**\nBy the end of this section, you will be able to:\n- Install and import external Python packages\n- Set up and authenticate with an AI API\n- Make API calls to a Large Language Model (LLM)\n- Create interactive AI-powered applications\n- Combine user input with AI responses for real-world use cases\n\n## **Why This Matters: Real-World AI/RAG/Agentic Applications**\n**In AI Systems:**\n- APIs are the foundation of all AI integrations\n- Understanding the API workflow is crucial for any AI application\n\n**In RAG Pipelines:**\n- RAG systems retrieve relevant documents, then use an LLM API to generate answers\n- This lesson teaches you the \"generation\" part of Retrieval-Augmented Generation\n\n**In Agentic AI:**\n- Agents use LLM APIs as their \"brain\" to process information and make decisions\n- Every agent action involves an API call similar to what you'll learn today\n\n## **Prerequisites**\n- Understanding of variables, strings, and f-strings (Lesson 01)\n- Ability to use `input()` function (Lesson 02)\n- A Gemini API key (from previous lesson 02.01)\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## **Learner Activity 1: Quick Recap - Calculator with Formatted Output**\n**Practice**: Review what you learned in previous lessons\n\n### **Exercise: Simple Calculator**\n\n**Task**: Create a program that:\n1. Asks the user for two numbers (use `input()`)\n2. Converts them to integers (use `int()`)\n3. Calculates their sum\n4. Prints a formatted string like: `\"5 + 3 = 8\"` (use f-string)\n\n**Expected Output**:\n```\nEnter first number: 5\nEnter second number: 3\n5 + 3 = 8\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Solution</summary>\n\n```python\n# **Get two numbers from user**\nnum1 = int(input(\"Enter first number: \"))\nnum2 = int(input(\"Enter second number: \"))\n\n# **Calculate sum**\ntotal = num1 + num2\n\n# **Print formatted output**\nprint(f\"{num1} + {num2} = {total}\")\n```\n\n**Why this works:**\n- `input()` captures user data as strings\n- `int()` converts strings to integers for math operations\n- F-strings create formatted output by embedding variables with `{}`\n- This pattern of input ‚Üí process ‚Üí formatted output is fundamental to all interactive programs\n\n</details>\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## **Instructor Activity 1: The 5-Step Toolbox Process**\n**Concept**: Building AI applications is like using power tools - follow 5 steps every time\n\n### **The Toolbox Analogy**\n\nThink of building AI applications like working with power tools. Every time you need to use a tool, you follow the same process:\n\n**Step 1: Purchase** üõí\n- You buy a toolbox from the store\n- Do this ONCE when you need new tools\n- *In Python: Install the package*\n\n**Step 2: Pick Out** üîß\n- You select the right tool from your toolbox\n- Do this at the start of EVERY project\n- *In Python: Import the library*\n\n**Step 3: Configure** ‚öôÔ∏è\n- You put in batteries, adjust speed/pressure settings\n- Configure the tool for your specific job\n- *In Python: Set up API authentication*\n\n**Step 4: Select Head** üî©\n- You attach the right screwdriver head (star, flathead, Phillips)\n- The tool body stays the same, but the head changes based on your need\n- *In Python: Choose which AI model to use*\n\n**Step 5: Use** ‚úÖ\n- Now you're ready to actually use the fully configured tool\n- Drive screws, drill holes, do the job!\n- *In Python: Make API calls to generate AI responses*\n\n---\n\n### **The 5 Steps in Code**\n\nLet's see how this translates to working with the Gemini AI API:\n\n```python\n# **Step 1: Purchase (Install) - Do ONCE per session**\n!pip install google-generativeai\n\n# **Step 2: Pick Out (Import) - Do in EVERY program**\nimport google.generativeai as genai\n\n# **Step 3: Configure (Set up authentication)**\ngenai.configure(api_key=\"your_api_key_here\")\n\n# **Step 4: Select Head (Choose model)**\nmodel = genai.GenerativeModel('gemini-2.5-flash')\n\n# **Step 5: Use (Generate response)**\nresponse = model.generate_content(\"Hello, AI!\")\nprint(response.text)\n```\n\n**Remember:** Steps 1-4 are setup. Step 5 is where the magic happens!\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## **Instructor Activity 2: Implementing the 5 Steps**\n**Concept**: Let's walk through each step with working code\n\n### **Step 1: Purchase the Toolbox (Install Package)**\n\n**What it does:** Downloads AI tools from Python's package repository (PyPI)\n\n**Word-by-word:**\n- `!` = Run a terminal command (Colab/Jupyter feature)\n- `pip` = Python's package installer (like an app store)\n- `install` = Download and set up\n- `-q` = Quiet mode (less output)\n- `google-generativeai` = Package name\n\n**Do this ONCE per session:**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Purchase (Install) - Run once per session\n",
    "!pip install -q google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n### **Steps 2-5: Pick Out, Configure, Select Head, Use**\n\nNow let's complete the remaining steps in one workflow:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Pick Out (Import with shorter nickname)\n",
    "import google.generativeai as genai\n",
    "from getpass import getpass\n",
    "\n",
    "# Step 3: Configure (Set up API authentication)\n",
    "api_key = getpass(\"Enter your Gemini API key: \")\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Step 4: Select Head (Create model instance)\n",
    "model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "\n",
    "# Step 5: Use (Generate AI response)\n",
    "question = \"What is Python programming in one sentence?\"\n",
    "response = model.generate_content(question)\n",
    "\n",
    "# Display the result\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Why this works:**\n\n**Step 2 (Import):**\n- `import google.generativeai as genai` ‚Üí Opens the toolbox, creates nickname \"genai\"\n- `from getpass import getpass` ‚Üí Imports secure input function\n\n**Step 3 (Configure):**\n- `getpass()` ‚Üí Securely captures your API key (hidden input)\n- `genai.configure(api_key=api_key)` ‚Üí Authenticates you with Google's AI servers\n\n**Step 4 (Select Head):**\n- `genai.GenerativeModel('gemini-2.5-flash')` ‚Üí Creates connection to specific AI model\n- `gemini-2.5-flash` is fast and efficient (like choosing a Phillips head screwdriver)\n\n**Step 5 (Use):**\n- `model.generate_content(question)` ‚Üí Sends question to AI, receives response\n- `response.text` ‚Üí Extracts the actual text from response object\n\n---\n\n### **Try Another Example**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps 2-5 together (API key already configured above)\n",
    "# Just need to use the model\n",
    "\n",
    "question = \"Explain APIs to a 10-year-old.\"\n",
    "response = model.generate_content(question)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice:** Once configured (Steps 1-4), you can use the model multiple times (Step 5)!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## **Learner Activity 2: Practice the 5 Steps**\n**Practice**: Implement the complete workflow yourself\n\n### **Exercise: Ask the AI About Machine Learning**\n\n**Task**: Follow all 5 steps to ask the AI: \"What is machine learning?\"\n\n**Steps to complete:**\n1. Install package (already done above, skip this)\n2. Import the library\n3. Configure with your API key (use getpass)\n4. Create model instance\n5. Generate response for \"What is machine learning?\"\n6. Print the response\n\n**Expected Output**:\n```\nEnter your Gemini API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\nMachine learning is a type of artificial intelligence...\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Solution</summary>\n\n```python\n# **Step 2: Import**\nimport google.generativeai as genai\nfrom getpass import getpass\n\n# **Step 3: Configure**\napi_key = getpass(\"Enter your Gemini API key: \")\ngenai.configure(api_key=api_key)\n\n# **Step 4: Create model instance**\nmodel = genai.GenerativeModel('gemini-2.5-flash')\n\n# **Step 5: Generate response**\nquestion = \"What is machine learning?\"\nresponse = model.generate_content(question)\n\n# **Print the AI's answer**\nprint(response.text)\n```\n\n**Why this works:**\n- You followed the complete 5-step workflow\n- Each step builds on the previous one\n- Step 1 (install) was already done, so we started at Step 2\n- Steps 2-4 are setup (import, configure, create model)\n- Step 5 is where you actually use the AI\n- This same pattern works for ANY AI API (OpenAI, Anthropic, etc.)\n\n**Congratulations!** You just made your first AI API call! üéâ\n\n</details>\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## **Instructor Activity 3: Building Interactive AI Applications**\n**Concept**: Combine user input with AI responses for real applications\n\n### **From Hard-Coded to Interactive**\n\nSo far we've used hard-coded questions. Real applications let users ask anything!\n\n**Pattern:**\n```\nUser Input ‚Üí AI Processing ‚Üí Formatted Output\n```\n\nLet's build an interactive Q&A program:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get question from user\n",
    "user_question = input(\"Ask me anything: \")\n",
    "\n",
    "# Send to AI (model already configured above)\n",
    "response = model.generate_content(user_question)\n",
    "\n",
    "# Print formatted output\n",
    "print(f\"\\nQuestion: {user_question}\")\n",
    "print(f\"Answer: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why this works:**\n",
    "- `input()` captures user's question dynamically\n",
    "- `model.generate_content()` sends it to AI\n",
    "- F-strings format the output professionally\n",
    "- `\\n` adds blank line for readability\n",
    "\n",
    "**This is the foundation of ChatGPT, Claude, and ALL AI chatbots!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## **Learner Activity 3: Build Your Interactive AI Q&A Program**\n**Practice**: Create a complete interactive AI application\n\n### **Exercise: AI-Powered Question Answering**\n\n**Task**: Create a program that:\n1. Sets up the AI (Steps 2-4)\n2. Asks user for a question\n3. Sends that question to Gemini\n4. Prints formatted output:\n   ```\n   Question: [user's question]\n   Answer: [AI's response]\n   ```\n\n**Expected Flow**:\n```\nEnter your Gemini API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\nAsk me anything: What is the speed of light?\n\nQuestion: What is the speed of light?\nAnswer: The speed of light in a vacuum is approximately 299,792,458 meters per second...\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Solution</summary>\n\n```python\n# **Import libraries**\nimport google.generativeai as genai\nfrom getpass import getpass\n\n# **Configure with API key**\napi_key = getpass(\"Enter your Gemini API key: \")\ngenai.configure(api_key=api_key)\n\n# **Create model**\nmodel = genai.GenerativeModel('gemini-2.5-flash')\n\n# **Get question from user**\nuser_question = input(\"Ask me anything: \")\n\n# **Generate AI response**\nresponse = model.generate_content(user_question)\n\n# **Print formatted output**\nprint(f\"\\nQuestion: {user_question}\")\nprint(f\"Answer: {response.text}\")\n```\n\n**Why this works:**\n- Follows the complete 5-step workflow\n- `input()` makes it interactive (accepts ANY question)\n- `generate_content()` sends question to AI\n- F-strings create professional formatted output\n- This pattern is used in production AI applications!\n\n**Congratulations!** You built a secure AI-powered application! This is the same pattern used in:\n- ChatGPT-style chatbots\n- AI writing assistants\n- Customer service bots\n- RAG systems (which add document retrieval before this step)\n\n</details>\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## **Optional Extra Practice**\n**Challenge yourself with these AI-powered applications**\n\nRemember: You've learned variables, strings, input, and basic API calls. Keep solutions simple using the 5-step pattern!\n\n---\n\n### **Challenge 1: AI Teacher**\n\n**Task**: Create a program that:\n1. Asks user for a topic they want to learn\n2. Creates a prompt: \"Explain [topic] in simple terms for a beginner\"\n3. Sends to AI and prints response\n\n**Expected Output**:\n```\nWhat do you want to learn about? photosynthesis\n\nLearning about: photosynthesis\n[AI explanation]\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Solution</summary>\n\n```python\n# **Get topic from user**\ntopic = input(\"What do you want to learn about? \")\n\n# **Create educational prompt (f-string to insert topic)**\nprompt = f\"Explain {topic} in simple terms for a beginner\"\n\n# **Send to AI (model already configured)**\nresponse = model.generate_content(prompt)\n\n# **Display**\nprint(f\"\\nLearning about: {topic}\")\nprint(response.text)\n```\n\n**Why this works:**\n- F-strings let you construct prompts dynamically\n- Adding \"in simple terms for a beginner\" guides the AI's response\n- This is called **prompt engineering** - crafting prompts for better results\n- You just built an AI tutor!\n\n</details>\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### **Challenge 2: AI Writing Assistant**\n\n**Task**: Create a program that:\n1. Asks user for a sentence they want to improve\n2. Sends prompt: \"Improve this sentence: [user's sentence]\"\n3. Prints both original and improved versions\n\n**Expected Output**:\n```\nEnter a sentence to improve: I goed to the store yesterday\n\nOriginal: I goed to the store yesterday\nImproved: [AI's corrected version]\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Solution</summary>\n\n```python\n# **Get sentence from user**\nsentence = input(\"Enter a sentence to improve: \")\n\n# **Create improvement prompt**\nprompt = f\"Improve this sentence: {sentence}\"\n\n# **Send to AI**\nresponse = model.generate_content(prompt)\n\n# **Display both versions**\nprint(f\"\\nOriginal: {sentence}\")\nprint(f\"Improved: {response.text}\")\n```\n\n**Why this works:**\n- This is a real writing assistant pattern\n- Tools like Grammarly use similar workflows\n- Capture input ‚Üí Send to AI with instructions ‚Üí Show comparison\n- You just built a mini Grammarly! üéâ\n\n</details>\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### **Challenge 3: AI Translator**\n\n**Task**: Create a program that:\n1. Asks user for text to translate\n2. Asks what language to translate to\n3. Sends prompt: \"Translate '[text]' to [language]\"\n4. Prints the translation\n\n**Expected Output**:\n```\nEnter text to translate: Hello, how are you?\nTranslate to which language? Spanish\n\nEnglish: Hello, how are you?\nSpanish: [AI translation]\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Solution</summary>\n\n```python\n# **Get text and target language**\ntext = input(\"Enter text to translate: \")\nlanguage = input(\"Translate to which language? \")\n\n# **Create translation prompt with TWO inputs**\nprompt = f\"Translate '{text}' to {language}\"\n\n# **Send to AI**\nresponse = model.generate_content(prompt)\n\n# **Display translation**\nprint(f\"\\nEnglish: {text}\")\nprint(f\"{language}: {response.text}\")\n```\n\n**Why this works:**\n- Uses **two inputs** to create a dynamic prompt\n- F-string combines both variables into one prompt\n- LLMs like Gemini are multilingual (hundreds of languages)\n- You just built Google Translate!\n\n</details>\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### **Challenge 4: AI Code Explainer**\n\n**Task**: Create a program that:\n1. Asks user to paste a line of Python code\n2. Sends prompt: \"Explain this Python code in simple terms: [code]\"\n3. Prints the explanation\n\n**Expected Output**:\n```\nEnter Python code to explain: print(f\"Hello, {name}\")\n\nCode: print(f\"Hello, {name}\")\nExplanation: [AI's explanation]\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Solution</summary>\n\n```python\n# **Get code from user**\ncode = input(\"Enter Python code to explain: \")\n\n# **Create explanation prompt**\nprompt = f\"Explain this Python code in simple terms: {code}\"\n\n# **Send to AI**\nresponse = model.generate_content(prompt)\n\n# **Display explanation**\nprint(f\"\\nCode: {code}\")\nprint(f\"Explanation: {response.text}\")\n```\n\n**Why this works:**\n- This is a code learning assistant\n- Tools like GitHub Copilot work similarly\n- When you don't understand code, AI can explain it\n- You just built your own AI programming tutor!\n\n</details>\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### **Challenge 5: AI Story Starter**\n\n**Task**: Create a program that:\n1. Asks user for a character name\n2. Asks for a setting (place)\n3. Sends prompt: \"Write the first paragraph of a story about [character] in [setting]\"\n4. Prints the story beginning\n\n**Expected Output**:\n```\nCharacter name: Luna\nSetting: a futuristic city on Mars\n\nYour story begins:\n[AI-generated story opening]\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Solution</summary>\n\n```python\n# **Get story elements from user**\ncharacter = input(\"Character name: \")\nsetting = input(\"Setting: \")\n\n# **Create story prompt with multiple inputs**\nprompt = f\"Write the first paragraph of a story about {character} in {setting}\"\n\n# **Send to AI**\nresponse = model.generate_content(prompt)\n\n# **Display story**\nprint(f\"\\nYour story begins:\")\nprint(response.text)\n```\n\n**Why this works:**\n- Combines multiple user inputs into a single creative prompt\n- This pattern is used in AI writing tools and game narrative generators\n- Better prompts = better AI output (prompt engineering!)\n- You just built a creative AI assistant!\n\n</details>\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### **Challenge 6: Multi-Step AI Workflow**\n\n**Task**: Create a program that:\n1. Asks user for a topic\n2. Generates a one-sentence explanation from AI\n3. Asks user if they want more detail\n4. If yes, sends a follow-up prompt for detailed explanation\n\n**Expected Output**:\n```\nEnter a topic: Quantum computing\n\nBrief explanation:\n[One sentence from AI]\n\nWant more detail? (yes/no): yes\n\nDetailed explanation:\n[Full explanation from AI]\n```\n\n**Hint**: You'll make TWO AI calls with different prompts"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Solution</summary>\n\n```python\n# **Get topic from user**\ntopic = input(\"Enter a topic: \")\n\n# **First AI call: Brief explanation**\nbrief_prompt = f\"Explain {topic} in one sentence\"\nbrief_response = model.generate_content(brief_prompt)\n\nprint(f\"\\nBrief explanation:\")\nprint(brief_response.text)\n\n# **Ask if user wants more**\nmore_detail = input(\"\\nWant more detail? (yes/no): \")\n\nif more_detail.lower() == \"yes\":\n    # Second AI call: Detailed explanation\n    detailed_prompt = f\"Explain {topic} in detail for a beginner\"\n    detailed_response = model.generate_content(detailed_prompt)\n    \n    print(f\"\\nDetailed explanation:\")\n    print(detailed_response.text)\nelse:\n    print(\"Thanks for using AI Teacher!\")\n```\n\n**Why this works:**\n- Makes TWO separate AI calls with different prompts\n- Uses conditional logic (`if`) to decide whether to make second call\n- `.lower()` handles \"Yes\", \"YES\", \"yes\" all the same way\n- This is a multi-step AI workflow - foundation for conversational AI!\n- You're starting to think like an AI application developer! üöÄ\n\n**Note:** You used `if` statement which we haven't formally learned yet - great preview of what's coming!\n\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### **Challenge 7: AI Text Humanizer**\n\n**Task**: Create a program that:\n1. Asks user for AI-generated or robotic-sounding text\n2. Sends it to the AI with a humanizer prompt\n3. Prints both original and humanized versions\n\n**Expected Output**:\n```\nEnter text to humanize: It is important to note that leveraging AI can facilitate better outcomes.\n\nOriginal: It is important to note that leveraging AI can facilitate better outcomes.\nHumanized: [More natural, conversational version]\n```\n\n**Hint**: Use a long, detailed prompt that tells the AI exactly how to write like a human!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>Solution</summary>\n\n```python\n# **Get text from user**\ntext = input(\"Enter text to humanize: \")\n\n# **Create humanizer prompt**\nhumanizer_prompt = f'''Rewrite this text to sound more natural and human:\n\n\"{text}\"\n\nWrite like a human:\n- One-sentence paragraphs for emphasis\n- Short paragraphs (3-4 sentences max)\n- Use contractions (don't, you're, it's)\n- Remove sentences restating the premise\n- No filler words\n- Cut qualifying phrases like \"if you focus on\" or \"when done correctly\"\n- Use direct statements\n- Remove hedge words: \"usually,\" \"often,\" \"generally\"\n- Delete setup phrases: \"It's worth noting that\" or \"The key point is\"\n\nNever use: delve, leverage, utilize, facilitate, underscore, showcase, navigate (as metaphor), realm, tapestry, foster, endeavor, embark, unleash\n\nReplace with: explore, use, help, shows, demonstrate, develop, try, start\n\nReplace (‚Äî) em dashes with periods, commas, or colons.\n\nDo not use (‚Äî) em dashes\n\nNever start paragraphs with: Furthermore, Moreover, In addition, Firstly, Secondly, In conclusion\n\nUse instead: So, But, Here's the thing, Listen, Now, or no transition\n\nMake it conversational, natural, and information-dense.'''\n\n# **Send to AI**\nmodel = genai.GenerativeModel('gemini-2.5-flash')\nresponse = model.generate_content(humanizer_prompt)\n\n# **Display both versions**\nprint(f\"\\nOriginal: {text}\")\nprint(f\"\\nHumanized:\\n{response.text}\")\n```\n\n**Why this works:**\nThis is a real AI-powered writing tool! By providing detailed instructions in the prompt, you're teaching the AI to:\n- Remove robotic corporate language (\"leverage,\" \"facilitate\")\n- Write conversationally with contractions\n- Cut filler and get to the point\n- Sound natural and human\n\n**The key:** A detailed, specific prompt produces better AI output. This is **prompt engineering** in action!\n\n**Real-world use:** Tools like Hemingway Editor and Grammarly use similar patterns to improve writing clarity and naturalness.\n\n</details>\n\n---\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## **Summary: What You've Learned**\n\nüéâ **The 5-Step Toolbox Process**\n1. Purchase (Install package) - Once per session\n2. Pick Out (Import library) - Every program\n3. Configure (Set up API key) - Authentication\n4. Select Head (Create model) - Choose AI model\n5. Use (Generate content) - Make API calls\n\n‚úÖ **Skills Acquired:**\n- Install external Python packages with pip\n- Import and configure AI libraries\n- Make API calls to Large Language Models\n- Build interactive AI-powered applications\n- Combine user input with AI responses\n- Use prompt engineering for better results\n\n**Your mini-apps:**\n- Take simple human input\n- Add specific prompts for different tasks\n- Use f-strings to combine input + prompt\n- Get AI-powered output that solves real problems\n\n---\n\n## **Looking Ahead: What's Next?**\n\n**Current Limitations:**\n- ‚ùå Can't have multi-turn conversations (no chat memory)\n- ‚ùå Can't process multiple documents\n- ‚ùå Can't make complex decisions\n- ‚ùå Can't repeat tasks automatically\n- ‚ùå Can't handle errors gracefully\n\n**To Build Production AI Apps, You Need:**\n1. **Lists & Loops** ‚Üí Store chat history, process multiple items\n2. **Dictionaries** ‚Üí Handle API responses (JSON), structured data\n3. **Functions** ‚Üí Reuse code, build modular pipelines\n4. **Conditionals** ‚Üí Make decisions, handle scenarios\n5. **Error Handling** ‚Üí Build robust applications\n\n**Course Roadmap:**\n```\n‚úÖ 01: Python Basics\n‚úÖ 02: Strings and Input\n‚úÖ 02.01: Generating and Storing API Keys\n‚úÖ 02.02: AI-Enabled Input/Output ‚Üê You are here\n\nüìç Next:\n‚Üí 03: Lists and Loops (chat history, batch processing)\n‚Üí 04: Dictionaries and JSON (API responses)\n‚Üí 05: Functions (modular code)\n‚Üí 06: Conditionals and Error Handling\n‚Üí 07-10: Build real AI applications!\n```\n\n---\n\n**Key Takeaway:** You went from zero to building AI-powered applications! But to go from \"cool demo\" to \"useful application\", master the foundational skills in upcoming lessons.\n\n**Keep going!** Every lesson unlocks new capabilities. üåü\n\nSee you in the next lesson! üöÄ"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}